## 1. new feature
## 2. MBC 구하기 - LR, RIDGE, LASSO, XGBOOST, MLP, SVM, RF


```python
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LogisticRegression
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pylab as plt
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
from category_encoders import TargetEncoder, LeaveOneOutEncoder
# 최대 행 수 설정
pd.set_option('display.max_rows', 500)
# 최대 열 수 설정
pd.set_option('display.max_columns', 500)
# 과학적 표기법 삭제
pd.set_option('display.float_format', '{:.2f}'.format)
```


```python
data = '../1111/CLICK_TARGET_0914_0701del_onehot_diff3.csv'
data_df = pd.read_csv(data, index_col=0)
```

TARGET : BID_COST * COUNT / DAY_DIFF(END_TIME - START_TIME)


```python
data_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AD_SET_ID_x</th>
      <th>AD_SET_NAME</th>
      <th>CAMP_ID</th>
      <th>CAMP_NAME</th>
      <th>ADV_ID</th>
      <th>BILLING_TYPE</th>
      <th>BID_COST</th>
      <th>CONFIG_BID_COST</th>
      <th>BID_TIME</th>
      <th>USE_CONFIG_YN</th>
      <th>COC_CONFIG_AD_COST</th>
      <th>FOC_CONFIG_AD_COST</th>
      <th>DAY_BUDGET_LIMIT_COST</th>
      <th>IMP_START_DATE</th>
      <th>IMP_END_DATE</th>
      <th>IMP_STRG_DOW</th>
      <th>IMP_STRG_HOUR</th>
      <th>BOOST_USE_CONFIG_YN</th>
      <th>EQD_USE_CONFIG_YN</th>
      <th>IMP_LIMIT_CNT</th>
      <th>GENDER_DIV</th>
      <th>AGE_STR</th>
      <th>ADDR_STR</th>
      <th>MACHINE_TYPE</th>
      <th>REG_TIME</th>
      <th>AD_SET_ACT_YN</th>
      <th>UPDATE_TIME</th>
      <th>TIME</th>
      <th>START_TIME</th>
      <th>END_TIME</th>
      <th>DAY_DIFF</th>
      <th>AD_TYPE</th>
      <th>AD_SET_ID_y</th>
      <th>ADDR_SO</th>
      <th>ADDR_GG</th>
      <th>ADDR_BS</th>
      <th>ADDR_IC</th>
      <th>ADDR_KN</th>
      <th>ADDR_DG</th>
      <th>ADDR_KB</th>
      <th>ADDR_ALL</th>
      <th>ADDR_DJ</th>
      <th>ADDR_JB</th>
      <th>ADDR_GJ</th>
      <th>ADDR_CN</th>
      <th>ADDR_CB</th>
      <th>ADDR_US</th>
      <th>ADDR_JN</th>
      <th>ADDR_GW</th>
      <th>ADDR_JJ</th>
      <th>ADDR_SJ</th>
      <th>MACH_ANDROID</th>
      <th>MACH_IOS</th>
      <th>MACH_PC</th>
      <th>AGE_40</th>
      <th>AGE_30</th>
      <th>AGE_50</th>
      <th>AGE_20</th>
      <th>AGE_60</th>
      <th>AGE_ALL</th>
      <th>AGE_10</th>
      <th>GENDER_F</th>
      <th>GENDER_M</th>
      <th>GENDER_N</th>
      <th>INV_M01A01001</th>
      <th>INV_M01A01002</th>
      <th>INV_M01A05001</th>
      <th>INV_M01A01003</th>
      <th>INV_M01M02001</th>
      <th>INV_M01M01001</th>
      <th>INV_M01M03001</th>
      <th>INV_M01A06001</th>
      <th>COUNT</th>
      <th>SUM_COST</th>
      <th>TARGET</th>
      <th>MCC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>857370631</td>
      <td>웅진북클럽19년1월_30이상여성</td>
      <td>857370629</td>
      <td>웅진북클럽</td>
      <td>wjbookclub@nhnent.com</td>
      <td>CPC</td>
      <td>300</td>
      <td>210</td>
      <td>2019-01-11 18:04:56</td>
      <td>1</td>
      <td>1500000</td>
      <td>0</td>
      <td>230000</td>
      <td>20190112</td>
      <td>20190131</td>
      <td>1111111</td>
      <td>111111111111111126024192.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>2019-01-03 오후 4:11:03</td>
      <td>1</td>
      <td>2019-01-11 18:04:56</td>
      <td>2019-01-11</td>
      <td>2019-01-11</td>
      <td>2019-01-14</td>
      <td>3</td>
      <td>FEED</td>
      <td>857370631.00</td>
      <td>0.28</td>
      <td>0.27</td>
      <td>0.09</td>
      <td>0.06</td>
      <td>0.05</td>
      <td>0.04</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.84</td>
      <td>0.16</td>
      <td>0.00</td>
      <td>0.41</td>
      <td>0.30</td>
      <td>0.23</td>
      <td>0.00</td>
      <td>0.06</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>1640</td>
      <td>492000</td>
      <td>164000</td>
      <td>546</td>
    </tr>
    <tr>
      <th>1</th>
      <td>857370753</td>
      <td>와이즈캠프_1월_3040</td>
      <td>857370751</td>
      <td>와이즈캠프_1월</td>
      <td>wisecamp@nhnent.com</td>
      <td>CPC</td>
      <td>300</td>
      <td>250</td>
      <td>2019-01-04 11:57:04</td>
      <td>1</td>
      <td>2000000</td>
      <td>0</td>
      <td>0</td>
      <td>20190104</td>
      <td>20190110</td>
      <td>1111111</td>
      <td>111111111111111126024192.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>2019-01-04 오전 11:57:04</td>
      <td>1</td>
      <td>2019-01-04 11:57:03</td>
      <td>2019-01-04</td>
      <td>2019-01-04</td>
      <td>2019-01-07</td>
      <td>3</td>
      <td>FEED</td>
      <td>857370753.00</td>
      <td>0.25</td>
      <td>0.28</td>
      <td>0.08</td>
      <td>0.06</td>
      <td>0.05</td>
      <td>0.05</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.04</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.76</td>
      <td>0.24</td>
      <td>0.00</td>
      <td>0.59</td>
      <td>0.41</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.74</td>
      <td>0.26</td>
      <td>0.00</td>
      <td>0.07</td>
      <td>0.93</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>427</td>
      <td>128100</td>
      <td>42700</td>
      <td>142</td>
    </tr>
    <tr>
      <th>2</th>
      <td>857370753</td>
      <td>와이즈캠프_1월_3040</td>
      <td>857370751</td>
      <td>와이즈캠프_1월</td>
      <td>wisecamp@nhnent.com</td>
      <td>CPC</td>
      <td>500</td>
      <td>410</td>
      <td>2019-01-07 17:19:03</td>
      <td>1</td>
      <td>2000000</td>
      <td>0</td>
      <td>0</td>
      <td>20190104</td>
      <td>20190110</td>
      <td>1111111</td>
      <td>111111111111111126024192.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>2019-01-04 오전 11:57:04</td>
      <td>1</td>
      <td>2019-01-07 17:19:02</td>
      <td>2019-01-07</td>
      <td>2019-01-07</td>
      <td>2019-01-10</td>
      <td>3</td>
      <td>FEED</td>
      <td>857370753.00</td>
      <td>0.26</td>
      <td>0.26</td>
      <td>0.09</td>
      <td>0.06</td>
      <td>0.04</td>
      <td>0.05</td>
      <td>0.04</td>
      <td>0.00</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.78</td>
      <td>0.22</td>
      <td>0.00</td>
      <td>0.56</td>
      <td>0.44</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.78</td>
      <td>0.22</td>
      <td>0.00</td>
      <td>0.04</td>
      <td>0.96</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>700</td>
      <td>350000</td>
      <td>116666</td>
      <td>233</td>
    </tr>
    <tr>
      <th>3</th>
      <td>857370753</td>
      <td>와이즈캠프_1월_3050</td>
      <td>857370751</td>
      <td>와이즈캠프_1월</td>
      <td>wisecamp@nhnent.com</td>
      <td>CPC</td>
      <td>500</td>
      <td>410</td>
      <td>2019-01-10 14:07:22</td>
      <td>1</td>
      <td>1000000</td>
      <td>0</td>
      <td>0</td>
      <td>20190104</td>
      <td>20190114</td>
      <td>1111111</td>
      <td>111111111111111126024192.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>2019-01-04 오전 11:57:04</td>
      <td>1</td>
      <td>2019-01-10 14:07:21</td>
      <td>2019-01-10</td>
      <td>2019-01-10</td>
      <td>2019-01-13</td>
      <td>3</td>
      <td>FEED</td>
      <td>857370753.00</td>
      <td>0.29</td>
      <td>0.26</td>
      <td>0.07</td>
      <td>0.07</td>
      <td>0.07</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.77</td>
      <td>0.23</td>
      <td>0.00</td>
      <td>0.50</td>
      <td>0.36</td>
      <td>0.15</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.64</td>
      <td>0.36</td>
      <td>0.00</td>
      <td>0.73</td>
      <td>0.27</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>1202</td>
      <td>601000</td>
      <td>200333</td>
      <td>400</td>
    </tr>
    <tr>
      <th>4</th>
      <td>857370753</td>
      <td>와이즈캠프_1월_3050</td>
      <td>857370751</td>
      <td>와이즈캠프_1월</td>
      <td>wisecamp@nhnent.com</td>
      <td>CPC</td>
      <td>500</td>
      <td>410</td>
      <td>2019-01-14 11:54:42</td>
      <td>1</td>
      <td>5000000</td>
      <td>0</td>
      <td>0</td>
      <td>20190104</td>
      <td>20190228</td>
      <td>1111111</td>
      <td>111111111111111126024192.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>2019-01-04 오전 11:57:04</td>
      <td>1</td>
      <td>2019-01-14 11:54:42</td>
      <td>2019-01-14</td>
      <td>2019-01-14</td>
      <td>2019-01-17</td>
      <td>3</td>
      <td>FEED</td>
      <td>857370753.00</td>
      <td>0.27</td>
      <td>0.27</td>
      <td>0.07</td>
      <td>0.06</td>
      <td>0.05</td>
      <td>0.04</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.78</td>
      <td>0.22</td>
      <td>0.00</td>
      <td>0.49</td>
      <td>0.34</td>
      <td>0.17</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.63</td>
      <td>0.37</td>
      <td>0.00</td>
      <td>0.77</td>
      <td>0.23</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>2340</td>
      <td>1170000</td>
      <td>390000</td>
      <td>780</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1518</th>
      <td>4081910851</td>
      <td>엑스핏 스마트워치</td>
      <td>3413587566</td>
      <td>앱스토리몰_2020년 6월</td>
      <td>appstory@nhnent.com</td>
      <td>CPC</td>
      <td>120</td>
      <td>120</td>
      <td>2020-06-15 17:14:58</td>
      <td>1</td>
      <td>2000000</td>
      <td>0</td>
      <td>30000</td>
      <td>20200615</td>
      <td>20200630</td>
      <td>1111111</td>
      <td>111111111111111126024192.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>2020-06-15 오후 5:14:58</td>
      <td>1</td>
      <td>2020-06-15 17:14:58</td>
      <td>2020-06-15</td>
      <td>2020-06-15</td>
      <td>2020-06-18</td>
      <td>3</td>
      <td>FEED</td>
      <td>4081910851.00</td>
      <td>0.23</td>
      <td>0.26</td>
      <td>0.11</td>
      <td>0.06</td>
      <td>0.06</td>
      <td>0.05</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.77</td>
      <td>0.23</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.17</td>
      <td>0.26</td>
      <td>0.07</td>
      <td>0.11</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.62</td>
      <td>0.00</td>
      <td>0.87</td>
      <td>0.13</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>618</td>
      <td>74160</td>
      <td>24720</td>
      <td>206</td>
    </tr>
    <tr>
      <th>1519</th>
      <td>4081910886</td>
      <td>클레온 칫솔 살균기2</td>
      <td>3413587566</td>
      <td>앱스토리몰_2020년 6월</td>
      <td>appstory@nhnent.com</td>
      <td>CPC</td>
      <td>140</td>
      <td>140</td>
      <td>2020-06-15 17:18:41</td>
      <td>1</td>
      <td>2000000</td>
      <td>0</td>
      <td>30000</td>
      <td>20200615</td>
      <td>20200630</td>
      <td>1111111</td>
      <td>111111111111111126024192.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>2020-06-15 오후 5:18:41</td>
      <td>1</td>
      <td>2020-06-15 17:18:40</td>
      <td>2020-06-15</td>
      <td>2020-06-15</td>
      <td>2020-06-18</td>
      <td>3</td>
      <td>FEED</td>
      <td>4081910886.00</td>
      <td>0.32</td>
      <td>0.27</td>
      <td>0.09</td>
      <td>0.05</td>
      <td>0.05</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.79</td>
      <td>0.21</td>
      <td>0.00</td>
      <td>0.34</td>
      <td>0.19</td>
      <td>0.27</td>
      <td>0.09</td>
      <td>0.11</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.54</td>
      <td>0.46</td>
      <td>0.00</td>
      <td>0.82</td>
      <td>0.17</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>109</td>
      <td>15260</td>
      <td>5086</td>
      <td>36</td>
    </tr>
    <tr>
      <th>1520</th>
      <td>4081911254</td>
      <td>엑스핏 스마트워치2</td>
      <td>3413587566</td>
      <td>앱스토리몰_2020년 6월</td>
      <td>appstory@nhnent.com</td>
      <td>CPC</td>
      <td>100</td>
      <td>100</td>
      <td>2020-06-22 14:58:33</td>
      <td>1</td>
      <td>1000000</td>
      <td>0</td>
      <td>30000</td>
      <td>20200622</td>
      <td>20200630</td>
      <td>1111111</td>
      <td>111111111111111126024192.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>2020-06-22 오후 2:58:33</td>
      <td>1</td>
      <td>2020-06-22 14:58:33</td>
      <td>2020-06-22</td>
      <td>2020-06-22</td>
      <td>2020-06-25</td>
      <td>3</td>
      <td>FEED</td>
      <td>4081911254.00</td>
      <td>0.32</td>
      <td>0.21</td>
      <td>0.10</td>
      <td>0.04</td>
      <td>0.04</td>
      <td>0.04</td>
      <td>0.05</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.80</td>
      <td>0.20</td>
      <td>0.00</td>
      <td>0.41</td>
      <td>0.21</td>
      <td>0.23</td>
      <td>0.08</td>
      <td>0.07</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.41</td>
      <td>0.59</td>
      <td>0.00</td>
      <td>0.82</td>
      <td>0.18</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>379</td>
      <td>37900</td>
      <td>12633</td>
      <td>126</td>
    </tr>
    <tr>
      <th>1521</th>
      <td>4081911289</td>
      <td>픽스 쿨 휴대용 선풍기2</td>
      <td>3413587566</td>
      <td>앱스토리몰_2020년 6월</td>
      <td>appstory@nhnent.com</td>
      <td>CPC</td>
      <td>100</td>
      <td>100</td>
      <td>2020-06-22 15:03:41</td>
      <td>1</td>
      <td>1000000</td>
      <td>0</td>
      <td>30000</td>
      <td>20200622</td>
      <td>20200630</td>
      <td>1111111</td>
      <td>111111111111111126024192.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>2020-06-22 오후 3:03:41</td>
      <td>1</td>
      <td>2020-06-22 15:03:40</td>
      <td>2020-06-22</td>
      <td>2020-06-22</td>
      <td>2020-06-24</td>
      <td>2</td>
      <td>FEED</td>
      <td>4081911289.00</td>
      <td>0.32</td>
      <td>0.25</td>
      <td>0.07</td>
      <td>0.05</td>
      <td>0.06</td>
      <td>0.04</td>
      <td>0.02</td>
      <td>0.00</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.00</td>
      <td>0.37</td>
      <td>0.20</td>
      <td>0.26</td>
      <td>0.07</td>
      <td>0.10</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.51</td>
      <td>0.49</td>
      <td>0.00</td>
      <td>0.95</td>
      <td>0.04</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>345</td>
      <td>34500</td>
      <td>17250</td>
      <td>172</td>
    </tr>
    <tr>
      <th>1522</th>
      <td>4081911779</td>
      <td>엑스핏 스마트워치3</td>
      <td>3413587566</td>
      <td>앱스토리몰_2020년 6월</td>
      <td>appstory@nhnent.com</td>
      <td>CPC</td>
      <td>100</td>
      <td>100</td>
      <td>2020-06-26 14:39:08</td>
      <td>1</td>
      <td>1000000</td>
      <td>0</td>
      <td>30000</td>
      <td>20200626</td>
      <td>20200630</td>
      <td>1111111</td>
      <td>111111111111111126024192.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>2020-06-26 오후 2:39:08</td>
      <td>1</td>
      <td>2020-06-26 14:39:07</td>
      <td>2020-06-26</td>
      <td>2020-06-26</td>
      <td>2020-06-28</td>
      <td>2</td>
      <td>FEED</td>
      <td>4081911779.00</td>
      <td>0.26</td>
      <td>0.25</td>
      <td>0.06</td>
      <td>0.04</td>
      <td>0.07</td>
      <td>0.04</td>
      <td>0.04</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.04</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.04</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.75</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.18</td>
      <td>0.22</td>
      <td>0.10</td>
      <td>0.08</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.62</td>
      <td>0.00</td>
      <td>0.82</td>
      <td>0.17</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
      <td>357</td>
      <td>35700</td>
      <td>17850</td>
      <td>178</td>
    </tr>
  </tbody>
</table>
<p>1523 rows × 76 columns</p>
</div>




```python
data_df['BOOST_USE_CONFIG_YN'].value_counts()
```




    0.00    1404
    1.00     119
    Name: BOOST_USE_CONFIG_YN, dtype: int64




```python
data_df['TARGET'].describe()
```




    count      1644.00
    mean     127529.92
    std      196136.47
    min          14.00
    25%       20295.50
    50%       61311.00
    75%      163838.50
    max     3054300.00
    Name: TARGET, dtype: float64




```python
data_df['DAY_DIFF'].describe()
```




    count   897.00
    mean      2.69
    std       0.67
    min       1.00
    25%       3.00
    50%       3.00
    75%       3.00
    max       3.00
    Name: DAY_DIFF, dtype: float64




```python
data_df.columns
```




    Index(['AD_SET_ID_x', 'AD_SET_NAME', 'CAMP_ID', 'CAMP_NAME', 'ADV_ID',
           'BILLING_TYPE', 'BID_COST', 'CONFIG_BID_COST', 'BID_TIME',
           'USE_CONFIG_YN', 'COC_CONFIG_AD_COST', 'FOC_CONFIG_AD_COST',
           'DAY_BUDGET_LIMIT_COST', 'IMP_START_DATE', 'IMP_END_DATE',
           'IMP_STRG_DOW', 'IMP_STRG_HOUR', 'BOOST_USE_CONFIG_YN',
           'EQD_USE_CONFIG_YN', 'IMP_LIMIT_CNT', 'GENDER_DIV', 'AGE_STR',
           'ADDR_STR', 'MACHINE_TYPE', 'REG_TIME', 'AD_SET_ACT_YN', 'UPDATE_TIME',
           'TIME', 'START_TIME', 'END_TIME', 'DAY_DIFF', 'AD_TYPE', 'AD_SET_ID_y',
           'ADDR_SO', 'ADDR_GG', 'ADDR_BS', 'ADDR_IC', 'ADDR_KN', 'ADDR_DG',
           'ADDR_KB', 'ADDR_ALL', 'ADDR_DJ', 'ADDR_JB', 'ADDR_GJ', 'ADDR_CN',
           'ADDR_CB', 'ADDR_US', 'ADDR_JN', 'ADDR_GW', 'ADDR_JJ', 'ADDR_SJ',
           'MACH_ANDROID', 'MACH_IOS', 'MACH_PC', 'AGE_40', 'AGE_30', 'AGE_50',
           'AGE_20', 'AGE_60', 'AGE_ALL', 'AGE_10', 'GENDER_F', 'GENDER_M',
           'GENDER_N', 'INV_M01A01001', 'INV_M01A01002', 'INV_M01A05001',
           'INV_M01A01003', 'INV_M01M02001', 'INV_M01M01001', 'INV_M01M03001',
           'INV_M01A06001', 'COUNT', 'SUM_COST', 'TARGET', 'MCC'],
          dtype='object')



DAY_DIFF 가 2일 이상인 것들만 사용
2020년 한국인 하루 평균 휴대폰 사용 분 * BID_COST의 평균(220 * BID_COST) https://www.donga.com/news/Economy/article/all/20200117/99262978/1


```python
cost_mean = int(data_df['BID_COST'].mean())
option = 220 * cost_mean
data_df = data_df[data_df['TARGET']<option]
```


```python
data_df['BID_COST'].hist(bins=30)
```




    <AxesSubplot:>




    
![png](output_11_1.png)
    



```python
data_df['BID_COST'].describe()
```




    count   1523.00
    mean     459.46
    std      262.88
    min      100.00
    25%      300.00
    50%      410.00
    75%      600.00
    max     3000.00
    Name: BID_COST, dtype: float64




```python
option
```




    100980




```python
plt.scatter(data_df['DAY_DIFF'].value_counts().index, data_df['DAY_DIFF'].value_counts())
plt.xlabel('DAY_DIFF', color='white')
plt.xlim((0, 50))
plt.ylabel('COUNT', color='white')
```




    Text(0, 0.5, 'COUNT')




    
![png](output_14_1.png)
    



```python
plt.scatter(data_df['DAY_DIFF'], data_df['TARGET'], alpha=0.2)
plt.xlim((0, 200))
plt.xlabel('DAY_DIFF', color='white')
plt.ylabel('TARGET', color='white')
```




    Text(0, 0.5, 'TARGET')




    
![png](output_15_1.png)
    



```python
data_df_1 = data_df[data_df['DAY_DIFF'] == 1].copy()
data_df_1 = data_df_1.drop(['AD_SET_ID','AD_SET_NAME', 'CAMP_ID', 'CAMP_NAME', 'ADV_ID',
                    'BILLING_TYPE','BID_TIME','USE_CONFIG_YN', 
                     'COC_CONFIG_AD_COST', 'FOC_CONFIG_AD_COST',
                     'DAY_BUDGET_LIMIT_COST', 'IMP_START_DATE', 'IMP_END_DATE','IMP_STRG_HOUR',
                     'IMP_LIMIT_CNT',
                     'REG_TIME', 'AD_SET_ACT_YN', 'UPDATE_TIME','TIME', 'START_TIME', 'END_TIME',
                     'DAY_DIFF','COUNT','SUM_COST','MCC'],axis=1)
```


```python
data_df_1
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BID_COST</th>
      <th>CONFIG_BID_COST</th>
      <th>IMP_STRG_DOW</th>
      <th>BOOST_USE_CONFIG_YN</th>
      <th>EQD_USE_CONFIG_YN</th>
      <th>GENDER_DIV</th>
      <th>AGE_STR</th>
      <th>ADDR_STR</th>
      <th>MACHINE_TYPE</th>
      <th>AD_TYPE</th>
      <th>TARGET</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>350</td>
      <td>290</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>123200</td>
    </tr>
    <tr>
      <th>13</th>
      <td>350</td>
      <td>250</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>F</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>80500</td>
    </tr>
    <tr>
      <th>17</th>
      <td>350</td>
      <td>250</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>145950</td>
    </tr>
    <tr>
      <th>25</th>
      <td>300</td>
      <td>250</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>42000</td>
    </tr>
    <tr>
      <th>26</th>
      <td>300</td>
      <td>250</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>278100</td>
    </tr>
    <tr>
      <th>40</th>
      <td>650</td>
      <td>650</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>155350</td>
    </tr>
    <tr>
      <th>41</th>
      <td>700</td>
      <td>700</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>315000</td>
    </tr>
    <tr>
      <th>57</th>
      <td>440</td>
      <td>310</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>86680</td>
    </tr>
    <tr>
      <th>59</th>
      <td>470</td>
      <td>330</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>F</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>86010</td>
    </tr>
    <tr>
      <th>85</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>546000</td>
    </tr>
    <tr>
      <th>198</th>
      <td>350</td>
      <td>250</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>20,30</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>43050</td>
    </tr>
    <tr>
      <th>204</th>
      <td>420</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>76020</td>
    </tr>
    <tr>
      <th>205</th>
      <td>440</td>
      <td>310</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>86240</td>
    </tr>
    <tr>
      <th>221</th>
      <td>120</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>480</td>
    </tr>
    <tr>
      <th>236</th>
      <td>300</td>
      <td>250</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>537000</td>
    </tr>
    <tr>
      <th>245</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>23000</td>
    </tr>
    <tr>
      <th>258</th>
      <td>430</td>
      <td>430</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>30960</td>
    </tr>
    <tr>
      <th>265</th>
      <td>290</td>
      <td>240</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>290</td>
    </tr>
    <tr>
      <th>283</th>
      <td>510</td>
      <td>360</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>M</td>
      <td>20,30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>64260</td>
    </tr>
    <tr>
      <th>284</th>
      <td>510</td>
      <td>420</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>215220</td>
    </tr>
    <tr>
      <th>289</th>
      <td>510</td>
      <td>420</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>327420</td>
    </tr>
    <tr>
      <th>290</th>
      <td>510</td>
      <td>420</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>428400</td>
    </tr>
    <tr>
      <th>291</th>
      <td>450</td>
      <td>370</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>162450</td>
    </tr>
    <tr>
      <th>292</th>
      <td>450</td>
      <td>370</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>52200</td>
    </tr>
    <tr>
      <th>304</th>
      <td>360</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>7560</td>
    </tr>
    <tr>
      <th>306</th>
      <td>360</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>17640</td>
    </tr>
    <tr>
      <th>308</th>
      <td>360</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>11880</td>
    </tr>
    <tr>
      <th>310</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>23000</td>
    </tr>
    <tr>
      <th>312</th>
      <td>750</td>
      <td>750</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>42000</td>
    </tr>
    <tr>
      <th>318</th>
      <td>350</td>
      <td>290</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>11900</td>
    </tr>
    <tr>
      <th>324</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>26000</td>
    </tr>
    <tr>
      <th>325</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>63500</td>
    </tr>
    <tr>
      <th>334</th>
      <td>380</td>
      <td>310</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>182020</td>
    </tr>
    <tr>
      <th>345</th>
      <td>500</td>
      <td>500</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>21000</td>
    </tr>
    <tr>
      <th>364</th>
      <td>300</td>
      <td>210</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>12900</td>
    </tr>
    <tr>
      <th>365</th>
      <td>300</td>
      <td>210</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>55200</td>
    </tr>
    <tr>
      <th>367</th>
      <td>400</td>
      <td>280</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>69200</td>
    </tr>
    <tr>
      <th>378</th>
      <td>560</td>
      <td>460</td>
      <td>1111111</td>
      <td>1</td>
      <td>1</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>226240</td>
    </tr>
    <tr>
      <th>384</th>
      <td>300</td>
      <td>210</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>167400</td>
    </tr>
    <tr>
      <th>385</th>
      <td>280</td>
      <td>200</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>154280</td>
    </tr>
    <tr>
      <th>389</th>
      <td>440</td>
      <td>310</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>256960</td>
    </tr>
    <tr>
      <th>390</th>
      <td>470</td>
      <td>330</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>F</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>383520</td>
    </tr>
    <tr>
      <th>394</th>
      <td>280</td>
      <td>280</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>105840</td>
    </tr>
    <tr>
      <th>395</th>
      <td>280</td>
      <td>280</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>107800</td>
    </tr>
    <tr>
      <th>406</th>
      <td>490</td>
      <td>350</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>336630</td>
    </tr>
    <tr>
      <th>407</th>
      <td>490</td>
      <td>350</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>415030</td>
    </tr>
    <tr>
      <th>408</th>
      <td>550</td>
      <td>390</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>656150</td>
    </tr>
    <tr>
      <th>409</th>
      <td>550</td>
      <td>390</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>310200</td>
    </tr>
    <tr>
      <th>411</th>
      <td>360</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>38160</td>
    </tr>
    <tr>
      <th>414</th>
      <td>440</td>
      <td>360</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>40920</td>
    </tr>
    <tr>
      <th>415</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>55000</td>
    </tr>
    <tr>
      <th>416</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>60000</td>
    </tr>
    <tr>
      <th>419</th>
      <td>360</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>37800</td>
    </tr>
    <tr>
      <th>424</th>
      <td>360</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>38520</td>
    </tr>
    <tr>
      <th>427</th>
      <td>440</td>
      <td>360</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>51480</td>
    </tr>
    <tr>
      <th>431</th>
      <td>400</td>
      <td>330</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>15600</td>
    </tr>
    <tr>
      <th>436</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>12700</td>
    </tr>
    <tr>
      <th>439</th>
      <td>110</td>
      <td>110</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>37290</td>
    </tr>
    <tr>
      <th>441</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>95500</td>
    </tr>
    <tr>
      <th>444</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>61500</td>
    </tr>
    <tr>
      <th>449</th>
      <td>360</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>22680</td>
    </tr>
    <tr>
      <th>455</th>
      <td>280</td>
      <td>200</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>F</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>162680</td>
    </tr>
    <tr>
      <th>456</th>
      <td>280</td>
      <td>200</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>F</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>161280</td>
    </tr>
    <tr>
      <th>457</th>
      <td>280</td>
      <td>200</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>F</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>159880</td>
    </tr>
    <tr>
      <th>462</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>13400</td>
    </tr>
    <tr>
      <th>470</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>21200</td>
    </tr>
    <tr>
      <th>481</th>
      <td>500</td>
      <td>500</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>39500</td>
    </tr>
    <tr>
      <th>483</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>41500</td>
    </tr>
    <tr>
      <th>488</th>
      <td>500</td>
      <td>500</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>19000</td>
    </tr>
    <tr>
      <th>504</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>13900</td>
    </tr>
    <tr>
      <th>505</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>31100</td>
    </tr>
    <tr>
      <th>507</th>
      <td>350</td>
      <td>350</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>521500</td>
    </tr>
    <tr>
      <th>538</th>
      <td>550</td>
      <td>550</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>88550</td>
    </tr>
    <tr>
      <th>566</th>
      <td>700</td>
      <td>700</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>233100</td>
    </tr>
    <tr>
      <th>595</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>14300</td>
    </tr>
    <tr>
      <th>596</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>8000</td>
    </tr>
    <tr>
      <th>601</th>
      <td>370</td>
      <td>260</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>F</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>19980</td>
    </tr>
    <tr>
      <th>603</th>
      <td>280</td>
      <td>200</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>246680</td>
    </tr>
    <tr>
      <th>609</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>72600</td>
    </tr>
    <tr>
      <th>625</th>
      <td>400</td>
      <td>400</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>49200</td>
    </tr>
    <tr>
      <th>627</th>
      <td>400</td>
      <td>400</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>37600</td>
    </tr>
    <tr>
      <th>633</th>
      <td>400</td>
      <td>330</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>78400</td>
    </tr>
    <tr>
      <th>657</th>
      <td>500</td>
      <td>500</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>366000</td>
    </tr>
    <tr>
      <th>659</th>
      <td>500</td>
      <td>500</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>304000</td>
    </tr>
    <tr>
      <th>685</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>202500</td>
    </tr>
    <tr>
      <th>694</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>278000</td>
    </tr>
    <tr>
      <th>709</th>
      <td>400</td>
      <td>330</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>58400</td>
    </tr>
    <tr>
      <th>774</th>
      <td>330</td>
      <td>230</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>17820</td>
    </tr>
    <tr>
      <th>802</th>
      <td>380</td>
      <td>270</td>
      <td>1101100</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>101460</td>
    </tr>
    <tr>
      <th>803</th>
      <td>380</td>
      <td>270</td>
      <td>1101100</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>232560</td>
    </tr>
    <tr>
      <th>808</th>
      <td>380</td>
      <td>270</td>
      <td>1111100</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>60800</td>
    </tr>
    <tr>
      <th>809</th>
      <td>380</td>
      <td>270</td>
      <td>1111100</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>266000</td>
    </tr>
    <tr>
      <th>823</th>
      <td>240</td>
      <td>170</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>163680</td>
    </tr>
    <tr>
      <th>835</th>
      <td>300</td>
      <td>210</td>
      <td>1111100</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>15000</td>
    </tr>
    <tr>
      <th>846</th>
      <td>900</td>
      <td>750</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>687600</td>
    </tr>
    <tr>
      <th>849</th>
      <td>700</td>
      <td>580</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>254100</td>
    </tr>
    <tr>
      <th>851</th>
      <td>800</td>
      <td>660</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>438400</td>
    </tr>
    <tr>
      <th>852</th>
      <td>840</td>
      <td>700</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>500640</td>
    </tr>
    <tr>
      <th>855</th>
      <td>650</td>
      <td>540</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>413400</td>
    </tr>
    <tr>
      <th>857</th>
      <td>650</td>
      <td>540</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>378300</td>
    </tr>
    <tr>
      <th>858</th>
      <td>650</td>
      <td>540</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>282750</td>
    </tr>
    <tr>
      <th>859</th>
      <td>600</td>
      <td>500</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>213600</td>
    </tr>
    <tr>
      <th>861</th>
      <td>700</td>
      <td>580</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>198100</td>
    </tr>
    <tr>
      <th>862</th>
      <td>750</td>
      <td>620</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>366750</td>
    </tr>
    <tr>
      <th>877</th>
      <td>1300</td>
      <td>1080</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>1028300</td>
    </tr>
    <tr>
      <th>882</th>
      <td>110</td>
      <td>110</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>1650</td>
    </tr>
    <tr>
      <th>884</th>
      <td>240</td>
      <td>200</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>19200</td>
    </tr>
    <tr>
      <th>892</th>
      <td>420</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30</td>
      <td>SO,GG</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>125580</td>
    </tr>
    <tr>
      <th>899</th>
      <td>800</td>
      <td>660</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>52800</td>
    </tr>
    <tr>
      <th>900</th>
      <td>800</td>
      <td>660</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>60000</td>
    </tr>
    <tr>
      <th>902</th>
      <td>880</td>
      <td>730</td>
      <td>1111111</td>
      <td>1</td>
      <td>1</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>151360</td>
    </tr>
    <tr>
      <th>906</th>
      <td>880</td>
      <td>730</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>85360</td>
    </tr>
    <tr>
      <th>911</th>
      <td>960</td>
      <td>800</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>540480</td>
    </tr>
    <tr>
      <th>919</th>
      <td>920</td>
      <td>760</td>
      <td>1111111</td>
      <td>1</td>
      <td>1</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>60720</td>
    </tr>
    <tr>
      <th>941</th>
      <td>800</td>
      <td>800</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>312000</td>
    </tr>
    <tr>
      <th>951</th>
      <td>800</td>
      <td>800</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>76800</td>
    </tr>
    <tr>
      <th>987</th>
      <td>330</td>
      <td>230</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>37950</td>
    </tr>
    <tr>
      <th>988</th>
      <td>330</td>
      <td>230</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>154440</td>
    </tr>
    <tr>
      <th>1021</th>
      <td>500</td>
      <td>500</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>1123000</td>
    </tr>
    <tr>
      <th>1052</th>
      <td>700</td>
      <td>580</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>245000</td>
    </tr>
    <tr>
      <th>1058</th>
      <td>800</td>
      <td>800</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>100000</td>
    </tr>
    <tr>
      <th>1063</th>
      <td>450</td>
      <td>370</td>
      <td>111000</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>27450</td>
    </tr>
    <tr>
      <th>1066</th>
      <td>450</td>
      <td>370</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>88200</td>
    </tr>
    <tr>
      <th>1083</th>
      <td>300</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>136200</td>
    </tr>
    <tr>
      <th>1084</th>
      <td>300</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>136200</td>
    </tr>
    <tr>
      <th>1086</th>
      <td>450</td>
      <td>370</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>7200</td>
    </tr>
    <tr>
      <th>1087</th>
      <td>540</td>
      <td>450</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>14040</td>
    </tr>
    <tr>
      <th>1096</th>
      <td>300</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>210000</td>
    </tr>
    <tr>
      <th>1106</th>
      <td>780</td>
      <td>650</td>
      <td>1111101</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>253500</td>
    </tr>
    <tr>
      <th>1110</th>
      <td>680</td>
      <td>560</td>
      <td>1111101</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>91800</td>
    </tr>
    <tr>
      <th>1115</th>
      <td>720</td>
      <td>600</td>
      <td>1111101</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>496080</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>300</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>3054300</td>
    </tr>
    <tr>
      <th>1119</th>
      <td>450</td>
      <td>320</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>6300</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>490</td>
      <td>350</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>105350</td>
    </tr>
    <tr>
      <th>1124</th>
      <td>650</td>
      <td>460</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>48750</td>
    </tr>
    <tr>
      <th>1131</th>
      <td>800</td>
      <td>800</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>135200</td>
    </tr>
    <tr>
      <th>1134</th>
      <td>800</td>
      <td>800</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>25600</td>
    </tr>
    <tr>
      <th>1136</th>
      <td>800</td>
      <td>800</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>9600</td>
    </tr>
    <tr>
      <th>1141</th>
      <td>500</td>
      <td>500</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>284500</td>
    </tr>
    <tr>
      <th>1147</th>
      <td>380</td>
      <td>270</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>476140</td>
    </tr>
    <tr>
      <th>1148</th>
      <td>400</td>
      <td>280</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>278000</td>
    </tr>
    <tr>
      <th>1168</th>
      <td>600</td>
      <td>500</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>25800</td>
    </tr>
    <tr>
      <th>1172</th>
      <td>3000</td>
      <td>2500</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>2253000</td>
    </tr>
    <tr>
      <th>1178</th>
      <td>420</td>
      <td>350</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>36540</td>
    </tr>
    <tr>
      <th>1208</th>
      <td>700</td>
      <td>580</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>241500</td>
    </tr>
    <tr>
      <th>1212</th>
      <td>600</td>
      <td>600</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>13800</td>
    </tr>
    <tr>
      <th>1215</th>
      <td>1300</td>
      <td>1300</td>
      <td>1111100</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>166400</td>
    </tr>
    <tr>
      <th>1224</th>
      <td>700</td>
      <td>580</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>92400</td>
    </tr>
    <tr>
      <th>1225</th>
      <td>900</td>
      <td>750</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>81000</td>
    </tr>
    <tr>
      <th>1226</th>
      <td>1100</td>
      <td>910</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>74800</td>
    </tr>
    <tr>
      <th>1227</th>
      <td>1100</td>
      <td>1100</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>133100</td>
    </tr>
    <tr>
      <th>1229</th>
      <td>700</td>
      <td>700</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>360500</td>
    </tr>
    <tr>
      <th>1237</th>
      <td>450</td>
      <td>370</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>116550</td>
    </tr>
    <tr>
      <th>1259</th>
      <td>1300</td>
      <td>1300</td>
      <td>1111100</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>136500</td>
    </tr>
    <tr>
      <th>1267</th>
      <td>950</td>
      <td>950</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>344850</td>
    </tr>
    <tr>
      <th>1269</th>
      <td>550</td>
      <td>550</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>360800</td>
    </tr>
    <tr>
      <th>1273</th>
      <td>800</td>
      <td>800</td>
      <td>111100</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>47200</td>
    </tr>
    <tr>
      <th>1275</th>
      <td>800</td>
      <td>800</td>
      <td>111100</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>19200</td>
    </tr>
    <tr>
      <th>1294</th>
      <td>500</td>
      <td>410</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>135000</td>
    </tr>
    <tr>
      <th>1296</th>
      <td>510</td>
      <td>360</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50,60</td>
      <td>SO,GG</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>53040</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>300</td>
      <td>300</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>180300</td>
    </tr>
    <tr>
      <th>1308</th>
      <td>540</td>
      <td>540</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>308340</td>
    </tr>
    <tr>
      <th>1312</th>
      <td>100</td>
      <td>100</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>400</td>
    </tr>
    <tr>
      <th>1320</th>
      <td>350</td>
      <td>250</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>58800</td>
    </tr>
    <tr>
      <th>1321</th>
      <td>380</td>
      <td>270</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>83600</td>
    </tr>
    <tr>
      <th>1325</th>
      <td>800</td>
      <td>800</td>
      <td>111100</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>85600</td>
    </tr>
    <tr>
      <th>1329</th>
      <td>800</td>
      <td>800</td>
      <td>111100</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>151200</td>
    </tr>
    <tr>
      <th>1331</th>
      <td>800</td>
      <td>800</td>
      <td>1111100</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>28000</td>
    </tr>
    <tr>
      <th>1332</th>
      <td>800</td>
      <td>800</td>
      <td>111100</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>75200</td>
    </tr>
    <tr>
      <th>1333</th>
      <td>800</td>
      <td>800</td>
      <td>111100</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>84800</td>
    </tr>
    <tr>
      <th>1341</th>
      <td>700</td>
      <td>580</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>280700</td>
    </tr>
    <tr>
      <th>1342</th>
      <td>900</td>
      <td>750</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>407700</td>
    </tr>
    <tr>
      <th>1343</th>
      <td>1200</td>
      <td>1000</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>714000</td>
    </tr>
    <tr>
      <th>1353</th>
      <td>800</td>
      <td>800</td>
      <td>111100</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>116800</td>
    </tr>
    <tr>
      <th>1361</th>
      <td>510</td>
      <td>360</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>22440</td>
    </tr>
    <tr>
      <th>1365</th>
      <td>510</td>
      <td>360</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>F</td>
      <td>20,30,40</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>20400</td>
    </tr>
    <tr>
      <th>1368</th>
      <td>720</td>
      <td>600</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>216000</td>
    </tr>
    <tr>
      <th>1370</th>
      <td>840</td>
      <td>700</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>680400</td>
    </tr>
    <tr>
      <th>1373</th>
      <td>850</td>
      <td>850</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>379100</td>
    </tr>
    <tr>
      <th>1375</th>
      <td>900</td>
      <td>900</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>306000</td>
    </tr>
    <tr>
      <th>1377</th>
      <td>320</td>
      <td>260</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>1280</td>
    </tr>
    <tr>
      <th>1378</th>
      <td>350</td>
      <td>290</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>54950</td>
    </tr>
    <tr>
      <th>1381</th>
      <td>350</td>
      <td>290</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>350</td>
    </tr>
    <tr>
      <th>1382</th>
      <td>350</td>
      <td>290</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>114800</td>
    </tr>
    <tr>
      <th>1383</th>
      <td>350</td>
      <td>290</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>DA</td>
      <td>1050</td>
    </tr>
    <tr>
      <th>1384</th>
      <td>350</td>
      <td>290</td>
      <td>1111111</td>
      <td>0</td>
      <td>0</td>
      <td>N</td>
      <td>40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>241850</td>
    </tr>
    <tr>
      <th>1390</th>
      <td>720</td>
      <td>600</td>
      <td>1111111</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>469440</td>
    </tr>
    <tr>
      <th>1394</th>
      <td>800</td>
      <td>800</td>
      <td>1111100</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>24000</td>
    </tr>
    <tr>
      <th>1395</th>
      <td>800</td>
      <td>800</td>
      <td>111100</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>44800</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>800</td>
      <td>800</td>
      <td>1111100</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>52800</td>
    </tr>
    <tr>
      <th>1397</th>
      <td>800</td>
      <td>800</td>
      <td>111100</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>88000</td>
    </tr>
    <tr>
      <th>1422</th>
      <td>900</td>
      <td>900</td>
      <td>111110</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>162000</td>
    </tr>
    <tr>
      <th>1423</th>
      <td>900</td>
      <td>900</td>
      <td>111110</td>
      <td>1</td>
      <td>0</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>276300</td>
    </tr>
    <tr>
      <th>1460</th>
      <td>900</td>
      <td>900</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>102600</td>
    </tr>
    <tr>
      <th>1488</th>
      <td>540</td>
      <td>450</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>163080</td>
    </tr>
    <tr>
      <th>1519</th>
      <td>400</td>
      <td>330</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>96800</td>
    </tr>
    <tr>
      <th>1522</th>
      <td>400</td>
      <td>330</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>62800</td>
    </tr>
    <tr>
      <th>1525</th>
      <td>450</td>
      <td>370</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>20,30,40,50</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>121500</td>
    </tr>
    <tr>
      <th>1537</th>
      <td>400</td>
      <td>400</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>175200</td>
    </tr>
    <tr>
      <th>1568</th>
      <td>630</td>
      <td>520</td>
      <td>1111111</td>
      <td>0</td>
      <td>1</td>
      <td>N</td>
      <td>30,40,50,60</td>
      <td>ALL</td>
      <td>ALL</td>
      <td>FEED</td>
      <td>207270</td>
    </tr>
  </tbody>
</table>
</div>




```python
plt.scatter(np.ones(len(data_df_1['TARGET'])), data_df_1['TARGET'])
#plt.xlim((0, 200))
```




    <matplotlib.collections.PathCollection at 0x1d7d25b2e08>




    
![png](output_18_1.png)
    



```python
plt.boxplot(data_df_1['TARGET'])
```




    {'whiskers': [<matplotlib.lines.Line2D at 0x1d7d2643dc8>,
      <matplotlib.lines.Line2D at 0x1d7d2658e08>],
     'caps': [<matplotlib.lines.Line2D at 0x1d7d2658f08>,
      <matplotlib.lines.Line2D at 0x1d7d2658f88>],
     'boxes': [<matplotlib.lines.Line2D at 0x1d7d2605748>],
     'medians': [<matplotlib.lines.Line2D at 0x1d7d265ef48>],
     'fliers': [<matplotlib.lines.Line2D at 0x1d7d265efc8>],
     'means': []}




    
![png](output_19_1.png)
    



```python
data_df_1['TARGET'].hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1d7d26d32c8>




    
![png](output_20_1.png)
    



```python
pd.DataFrame((data_df['DAY_DIFF'].value_counts(),data_df['DAY_DIFF'].value_counts()/len(data_df)), 
             index = ["count", "percent"]).T.sort_values(by=["count"], ascending=False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>percent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>683.00</td>
      <td>0.69</td>
    </tr>
    <tr>
      <th>1</th>
      <td>102.00</td>
      <td>0.10</td>
    </tr>
    <tr>
      <th>2</th>
      <td>72.00</td>
      <td>0.07</td>
    </tr>
    <tr>
      <th>4</th>
      <td>67.00</td>
      <td>0.07</td>
    </tr>
    <tr>
      <th>3</th>
      <td>65.00</td>
      <td>0.07</td>
    </tr>
  </tbody>
</table>
</div>



DAY_DIFF 피처에 넣음


```python
data_df.columns
```




    Index(['AD_SET_ID', 'AD_SET_NAME', 'CAMP_ID', 'CAMP_NAME', 'ADV_ID',
           'BILLING_TYPE', 'BID_COST', 'CONFIG_BID_COST', 'BID_TIME',
           'USE_CONFIG_YN', 'COC_CONFIG_AD_COST', 'FOC_CONFIG_AD_COST',
           'DAY_BUDGET_LIMIT_COST', 'IMP_START_DATE', 'IMP_END_DATE',
           'IMP_STRG_DOW', 'IMP_STRG_HOUR', 'BOOST_USE_CONFIG_YN',
           'EQD_USE_CONFIG_YN', 'IMP_LIMIT_CNT', 'GENDER_DIV', 'AGE_STR',
           'ADDR_STR', 'MACHINE_TYPE', 'REG_TIME', 'AD_SET_ACT_YN', 'UPDATE_TIME',
           'TIME', 'START_TIME', 'END_TIME', 'DAY_DIFF', 'AD_TYPE', 'ADDR_SO',
           'ADDR_GG', 'ADDR_BS', 'ADDR_IC', 'ADDR_KN', 'ADDR_DG', 'ADDR_KB',
           'ADDR_ALL', 'ADDR_DJ', 'ADDR_JB', 'ADDR_GJ', 'ADDR_CN', 'ADDR_CB',
           'ADDR_US', 'ADDR_JN', 'ADDR_GW', 'ADDR_JJ', 'ADDR_SJ', 'MACH_ANDROID',
           'MACH_IOS', 'MACH_PC', 'AGE_40', 'AGE_30', 'AGE_50', 'AGE_20', 'AGE_60',
           'AGE_ALL', 'AGE_10', 'GENDER_F', 'GENDER_M', 'GENDER_N',
           'INV_M01A01001', 'INV_M01A01002', 'INV_M01A05001', 'INV_M01A01003',
           'INV_M01M02001', 'INV_M01M01001', 'INV_M01M03001', 'INV_M01A06001',
           'COUNT', 'SUM_COST', 'TARGET', 'MCC'],
          dtype='object')




```python
data_df.shape
```




    (989, 75)




```python
data_df.columns
```




    Index(['AD_SET_ID_x', 'AD_SET_NAME', 'CAMP_ID', 'CAMP_NAME', 'ADV_ID',
           'BILLING_TYPE', 'BID_COST', 'CONFIG_BID_COST', 'BID_TIME',
           'USE_CONFIG_YN', 'COC_CONFIG_AD_COST', 'FOC_CONFIG_AD_COST',
           'DAY_BUDGET_LIMIT_COST', 'IMP_START_DATE', 'IMP_END_DATE',
           'IMP_STRG_DOW', 'IMP_STRG_HOUR', 'BOOST_USE_CONFIG_YN',
           'EQD_USE_CONFIG_YN', 'IMP_LIMIT_CNT', 'GENDER_DIV', 'AGE_STR',
           'ADDR_STR', 'MACHINE_TYPE', 'REG_TIME', 'AD_SET_ACT_YN', 'UPDATE_TIME',
           'TIME', 'START_TIME', 'END_TIME', 'DAY_DIFF', 'AD_TYPE', 'AD_SET_ID_y',
           'ADDR_SO', 'ADDR_GG', 'ADDR_BS', 'ADDR_IC', 'ADDR_KN', 'ADDR_DG',
           'ADDR_KB', 'ADDR_ALL', 'ADDR_DJ', 'ADDR_JB', 'ADDR_GJ', 'ADDR_CN',
           'ADDR_CB', 'ADDR_US', 'ADDR_JN', 'ADDR_GW', 'ADDR_JJ', 'ADDR_SJ',
           'MACH_ANDROID', 'MACH_IOS', 'MACH_PC', 'AGE_40', 'AGE_30', 'AGE_50',
           'AGE_20', 'AGE_60', 'AGE_ALL', 'AGE_10', 'GENDER_F', 'GENDER_M',
           'GENDER_N', 'INV_M01A01001', 'INV_M01A01002', 'INV_M01A05001',
           'INV_M01A01003', 'INV_M01M02001', 'INV_M01M01001', 'INV_M01M03001',
           'INV_M01A06001', 'COUNT', 'SUM_COST', 'TARGET', 'MCC'],
          dtype='object')



corr


```python
data = data_df.drop(['AD_SET_ID_x','AD_SET_ID_y','AD_SET_NAME', 'CAMP_ID', 'CAMP_NAME', 'ADV_ID',
                    'BILLING_TYPE','BID_TIME','USE_CONFIG_YN', 
                     'COC_CONFIG_AD_COST', 'FOC_CONFIG_AD_COST',
                     'DAY_BUDGET_LIMIT_COST', 'IMP_START_DATE', 'IMP_END_DATE','IMP_STRG_HOUR',
                     'IMP_LIMIT_CNT',
                     'REG_TIME', 'AD_SET_ACT_YN', 'UPDATE_TIME','TIME', 'START_TIME', 'END_TIME',
                     'DAY_DIFF','COUNT','SUM_COST','MCC',
                    'GENDER_DIV','AGE_STR','ADDR_STR','MACHINE_TYPE'],axis=1)
data = data.loc[:,['BID_COST','CONFIG_BID_COST','TARGET']]
corr = data.corr(method = 'pearson')
print(corr)
```

                     BID_COST  CONFIG_BID_COST  TARGET
    BID_COST             1.00             0.97    0.39
    CONFIG_BID_COST      0.97             1.00    0.35
    TARGET               0.39             0.35    1.00


사용할 Feature 선정


```python
data = data_df.drop(['AD_SET_ID_x','AD_SET_ID_y','AD_SET_NAME', 'CAMP_ID', 'CAMP_NAME', 'ADV_ID',
                    'BILLING_TYPE','BID_TIME','USE_CONFIG_YN', 
                     'COC_CONFIG_AD_COST', 'FOC_CONFIG_AD_COST',
                     'DAY_BUDGET_LIMIT_COST', 'IMP_START_DATE', 'IMP_END_DATE','IMP_STRG_HOUR',
                     'IMP_LIMIT_CNT',
                     'REG_TIME', 'AD_SET_ACT_YN', 'UPDATE_TIME','TIME', 'START_TIME', 'END_TIME',
                     'DAY_DIFF','COUNT','SUM_COST','MCC',
                    'GENDER_DIV','AGE_STR','ADDR_STR','MACHINE_TYPE'],axis=1)
#y_label = data['TARGET']
y_label = np.log(data['TARGET'])
del data['TARGET']
df = data
```

TargetEncoder


```python
y_label
```




    1      10.66
    6      10.67
    7      11.50
    8      10.66
    11     11.43
            ... 
    1518   10.12
    1519    8.53
    1520    9.44
    1521    9.76
    1522    9.79
    Name: TARGET, Length: 897, dtype: float64




```python
y_mean = y_label.describe().mean()
enc = TargetEncoder(cols=['IMP_STRG_DOW','AD_TYPE'])
index_DOW = data[data['IMP_STRG_DOW'].isnull()].index
data.loc[index_DOW, ['IMP_STRG_DOW']]=y_mean
training_set = enc.fit_transform(data, y_label)

#del training_set['index']
data = training_set
data['BOOST_USE_CONFIG_YN'] = data['BOOST_USE_CONFIG_YN'].astype('int')
```


```python
X_features = pd.DataFrame(data, columns = data.columns)
```


```python
X_features.shape
```




    (897, 45)




```python
X_features
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BID_COST</th>
      <th>CONFIG_BID_COST</th>
      <th>IMP_STRG_DOW</th>
      <th>BOOST_USE_CONFIG_YN</th>
      <th>EQD_USE_CONFIG_YN</th>
      <th>AD_TYPE</th>
      <th>ADDR_SO</th>
      <th>ADDR_GG</th>
      <th>ADDR_BS</th>
      <th>ADDR_IC</th>
      <th>ADDR_KN</th>
      <th>ADDR_DG</th>
      <th>ADDR_KB</th>
      <th>ADDR_ALL</th>
      <th>ADDR_DJ</th>
      <th>ADDR_JB</th>
      <th>ADDR_GJ</th>
      <th>ADDR_CN</th>
      <th>ADDR_CB</th>
      <th>ADDR_US</th>
      <th>ADDR_JN</th>
      <th>ADDR_GW</th>
      <th>ADDR_JJ</th>
      <th>ADDR_SJ</th>
      <th>MACH_ANDROID</th>
      <th>MACH_IOS</th>
      <th>MACH_PC</th>
      <th>AGE_40</th>
      <th>AGE_30</th>
      <th>AGE_50</th>
      <th>AGE_20</th>
      <th>AGE_60</th>
      <th>AGE_ALL</th>
      <th>AGE_10</th>
      <th>GENDER_F</th>
      <th>GENDER_M</th>
      <th>GENDER_N</th>
      <th>INV_M01A01001</th>
      <th>INV_M01A01002</th>
      <th>INV_M01A05001</th>
      <th>INV_M01A01003</th>
      <th>INV_M01M02001</th>
      <th>INV_M01M01001</th>
      <th>INV_M01M03001</th>
      <th>INV_M01A06001</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>300</td>
      <td>250</td>
      <td>9.95</td>
      <td>0</td>
      <td>0</td>
      <td>10.14</td>
      <td>0.25</td>
      <td>0.28</td>
      <td>0.08</td>
      <td>0.06</td>
      <td>0.05</td>
      <td>0.05</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.04</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.76</td>
      <td>0.24</td>
      <td>0.00</td>
      <td>0.59</td>
      <td>0.41</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.74</td>
      <td>0.26</td>
      <td>0.00</td>
      <td>0.07</td>
      <td>0.93</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>300</td>
      <td>210</td>
      <td>9.95</td>
      <td>0</td>
      <td>0</td>
      <td>10.14</td>
      <td>0.34</td>
      <td>0.21</td>
      <td>0.07</td>
      <td>0.09</td>
      <td>0.04</td>
      <td>0.06</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.02</td>
      <td>0.04</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.84</td>
      <td>0.16</td>
      <td>0.00</td>
      <td>0.41</td>
      <td>0.26</td>
      <td>0.27</td>
      <td>0.00</td>
      <td>0.06</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>300</td>
      <td>210</td>
      <td>9.95</td>
      <td>0</td>
      <td>0</td>
      <td>10.14</td>
      <td>0.29</td>
      <td>0.28</td>
      <td>0.10</td>
      <td>0.05</td>
      <td>0.03</td>
      <td>0.04</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.80</td>
      <td>0.20</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.30</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.07</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>300</td>
      <td>210</td>
      <td>9.95</td>
      <td>0</td>
      <td>0</td>
      <td>10.14</td>
      <td>0.30</td>
      <td>0.20</td>
      <td>0.10</td>
      <td>0.05</td>
      <td>0.06</td>
      <td>0.04</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.04</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.84</td>
      <td>0.16</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.30</td>
      <td>0.22</td>
      <td>0.00</td>
      <td>0.08</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>11</th>
      <td>350</td>
      <td>250</td>
      <td>9.95</td>
      <td>0</td>
      <td>0</td>
      <td>10.14</td>
      <td>0.28</td>
      <td>0.23</td>
      <td>0.10</td>
      <td>0.07</td>
      <td>0.06</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.78</td>
      <td>0.22</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.35</td>
      <td>0.23</td>
      <td>0.00</td>
      <td>0.05</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1518</th>
      <td>120</td>
      <td>120</td>
      <td>9.95</td>
      <td>0</td>
      <td>0</td>
      <td>10.14</td>
      <td>0.23</td>
      <td>0.26</td>
      <td>0.11</td>
      <td>0.06</td>
      <td>0.06</td>
      <td>0.05</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.77</td>
      <td>0.23</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.17</td>
      <td>0.26</td>
      <td>0.07</td>
      <td>0.11</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.62</td>
      <td>0.00</td>
      <td>0.87</td>
      <td>0.13</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1519</th>
      <td>140</td>
      <td>140</td>
      <td>9.95</td>
      <td>0</td>
      <td>0</td>
      <td>10.14</td>
      <td>0.32</td>
      <td>0.27</td>
      <td>0.09</td>
      <td>0.05</td>
      <td>0.05</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.79</td>
      <td>0.21</td>
      <td>0.00</td>
      <td>0.34</td>
      <td>0.19</td>
      <td>0.27</td>
      <td>0.09</td>
      <td>0.11</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.54</td>
      <td>0.46</td>
      <td>0.00</td>
      <td>0.82</td>
      <td>0.17</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1520</th>
      <td>100</td>
      <td>100</td>
      <td>9.95</td>
      <td>0</td>
      <td>0</td>
      <td>10.14</td>
      <td>0.32</td>
      <td>0.21</td>
      <td>0.10</td>
      <td>0.04</td>
      <td>0.04</td>
      <td>0.04</td>
      <td>0.05</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.80</td>
      <td>0.20</td>
      <td>0.00</td>
      <td>0.41</td>
      <td>0.21</td>
      <td>0.23</td>
      <td>0.08</td>
      <td>0.07</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.41</td>
      <td>0.59</td>
      <td>0.00</td>
      <td>0.82</td>
      <td>0.18</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1521</th>
      <td>100</td>
      <td>100</td>
      <td>9.95</td>
      <td>0</td>
      <td>0</td>
      <td>10.14</td>
      <td>0.32</td>
      <td>0.25</td>
      <td>0.07</td>
      <td>0.05</td>
      <td>0.06</td>
      <td>0.04</td>
      <td>0.02</td>
      <td>0.00</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.00</td>
      <td>0.37</td>
      <td>0.20</td>
      <td>0.26</td>
      <td>0.07</td>
      <td>0.10</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.51</td>
      <td>0.49</td>
      <td>0.00</td>
      <td>0.95</td>
      <td>0.04</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1522</th>
      <td>100</td>
      <td>100</td>
      <td>9.95</td>
      <td>0</td>
      <td>0</td>
      <td>10.14</td>
      <td>0.26</td>
      <td>0.25</td>
      <td>0.06</td>
      <td>0.04</td>
      <td>0.07</td>
      <td>0.04</td>
      <td>0.04</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.04</td>
      <td>0.02</td>
      <td>0.03</td>
      <td>0.02</td>
      <td>0.04</td>
      <td>0.01</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>0.75</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.18</td>
      <td>0.22</td>
      <td>0.10</td>
      <td>0.08</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.62</td>
      <td>0.00</td>
      <td>0.82</td>
      <td>0.17</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>897 rows × 45 columns</p>
</div>



MinMaxScaler


```python
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_MinMax = scaler.fit_transform(X_features)
X_features = pd.DataFrame(X_MinMax, columns = data.columns)
X_features.columns
```




    Index(['BID_COST', 'CONFIG_BID_COST', 'IMP_STRG_DOW', 'BOOST_USE_CONFIG_YN',
           'EQD_USE_CONFIG_YN', 'AD_TYPE', 'ADDR_SO', 'ADDR_GG', 'ADDR_BS',
           'ADDR_IC', 'ADDR_KN', 'ADDR_DG', 'ADDR_KB', 'ADDR_ALL', 'ADDR_DJ',
           'ADDR_JB', 'ADDR_GJ', 'ADDR_CN', 'ADDR_CB', 'ADDR_US', 'ADDR_JN',
           'ADDR_GW', 'ADDR_JJ', 'ADDR_SJ', 'MACH_ANDROID', 'MACH_IOS', 'MACH_PC',
           'AGE_40', 'AGE_30', 'AGE_50', 'AGE_20', 'AGE_60', 'AGE_ALL', 'AGE_10',
           'GENDER_F', 'GENDER_M', 'GENDER_N', 'INV_M01A01001', 'INV_M01A01002',
           'INV_M01A05001', 'INV_M01A01003', 'INV_M01M02001', 'INV_M01M01001',
           'INV_M01M03001', 'INV_M01A06001'],
          dtype='object')




```python
X_features
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BID_COST</th>
      <th>CONFIG_BID_COST</th>
      <th>IMP_STRG_DOW</th>
      <th>BOOST_USE_CONFIG_YN</th>
      <th>EQD_USE_CONFIG_YN</th>
      <th>AD_TYPE</th>
      <th>ADDR_SO</th>
      <th>ADDR_GG</th>
      <th>ADDR_BS</th>
      <th>ADDR_IC</th>
      <th>ADDR_KN</th>
      <th>ADDR_DG</th>
      <th>ADDR_KB</th>
      <th>ADDR_ALL</th>
      <th>ADDR_DJ</th>
      <th>ADDR_JB</th>
      <th>ADDR_GJ</th>
      <th>ADDR_CN</th>
      <th>ADDR_CB</th>
      <th>ADDR_US</th>
      <th>ADDR_JN</th>
      <th>ADDR_GW</th>
      <th>ADDR_JJ</th>
      <th>ADDR_SJ</th>
      <th>MACH_ANDROID</th>
      <th>MACH_IOS</th>
      <th>MACH_PC</th>
      <th>AGE_40</th>
      <th>AGE_30</th>
      <th>AGE_50</th>
      <th>AGE_20</th>
      <th>AGE_60</th>
      <th>AGE_ALL</th>
      <th>AGE_10</th>
      <th>GENDER_F</th>
      <th>GENDER_M</th>
      <th>GENDER_N</th>
      <th>INV_M01A01001</th>
      <th>INV_M01A01002</th>
      <th>INV_M01A05001</th>
      <th>INV_M01A01003</th>
      <th>INV_M01M02001</th>
      <th>INV_M01M01001</th>
      <th>INV_M01M03001</th>
      <th>INV_M01A06001</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.17</td>
      <td>0.12</td>
      <td>0.48</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.25</td>
      <td>0.28</td>
      <td>0.14</td>
      <td>0.21</td>
      <td>0.17</td>
      <td>0.21</td>
      <td>0.08</td>
      <td>0.01</td>
      <td>0.11</td>
      <td>0.11</td>
      <td>0.07</td>
      <td>0.18</td>
      <td>0.06</td>
      <td>0.08</td>
      <td>0.09</td>
      <td>0.17</td>
      <td>0.10</td>
      <td>0.05</td>
      <td>0.76</td>
      <td>0.24</td>
      <td>0.00</td>
      <td>0.59</td>
      <td>0.41</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.74</td>
      <td>0.26</td>
      <td>0.00</td>
      <td>0.07</td>
      <td>0.93</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.17</td>
      <td>0.09</td>
      <td>0.48</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.34</td>
      <td>0.21</td>
      <td>0.14</td>
      <td>0.33</td>
      <td>0.14</td>
      <td>0.23</td>
      <td>0.02</td>
      <td>0.00</td>
      <td>0.05</td>
      <td>0.25</td>
      <td>0.20</td>
      <td>0.15</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>0.07</td>
      <td>0.11</td>
      <td>0.07</td>
      <td>0.10</td>
      <td>0.84</td>
      <td>0.16</td>
      <td>0.00</td>
      <td>0.41</td>
      <td>0.26</td>
      <td>0.27</td>
      <td>0.00</td>
      <td>0.13</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.17</td>
      <td>0.09</td>
      <td>0.48</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.29</td>
      <td>0.28</td>
      <td>0.18</td>
      <td>0.17</td>
      <td>0.11</td>
      <td>0.15</td>
      <td>0.10</td>
      <td>0.01</td>
      <td>0.11</td>
      <td>0.11</td>
      <td>0.18</td>
      <td>0.11</td>
      <td>0.08</td>
      <td>0.06</td>
      <td>0.04</td>
      <td>0.16</td>
      <td>0.06</td>
      <td>0.07</td>
      <td>0.80</td>
      <td>0.20</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.30</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.14</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.17</td>
      <td>0.09</td>
      <td>0.48</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.30</td>
      <td>0.20</td>
      <td>0.19</td>
      <td>0.16</td>
      <td>0.19</td>
      <td>0.18</td>
      <td>0.09</td>
      <td>0.01</td>
      <td>0.11</td>
      <td>0.14</td>
      <td>0.24</td>
      <td>0.16</td>
      <td>0.07</td>
      <td>0.01</td>
      <td>0.04</td>
      <td>0.34</td>
      <td>0.07</td>
      <td>0.15</td>
      <td>0.84</td>
      <td>0.16</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.30</td>
      <td>0.22</td>
      <td>0.00</td>
      <td>0.16</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.21</td>
      <td>0.12</td>
      <td>0.48</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.28</td>
      <td>0.23</td>
      <td>0.19</td>
      <td>0.23</td>
      <td>0.22</td>
      <td>0.14</td>
      <td>0.10</td>
      <td>0.01</td>
      <td>0.11</td>
      <td>0.09</td>
      <td>0.17</td>
      <td>0.12</td>
      <td>0.09</td>
      <td>0.04</td>
      <td>0.05</td>
      <td>0.09</td>
      <td>0.05</td>
      <td>0.11</td>
      <td>0.78</td>
      <td>0.22</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.35</td>
      <td>0.23</td>
      <td>0.00</td>
      <td>0.10</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>892</th>
      <td>0.02</td>
      <td>0.02</td>
      <td>0.48</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.23</td>
      <td>0.26</td>
      <td>0.20</td>
      <td>0.21</td>
      <td>0.20</td>
      <td>0.19</td>
      <td>0.07</td>
      <td>0.01</td>
      <td>0.10</td>
      <td>0.13</td>
      <td>0.11</td>
      <td>0.18</td>
      <td>0.09</td>
      <td>0.06</td>
      <td>0.06</td>
      <td>0.25</td>
      <td>0.08</td>
      <td>0.11</td>
      <td>0.77</td>
      <td>0.23</td>
      <td>0.00</td>
      <td>0.39</td>
      <td>0.17</td>
      <td>0.26</td>
      <td>0.07</td>
      <td>0.21</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.62</td>
      <td>0.00</td>
      <td>0.87</td>
      <td>0.13</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>893</th>
      <td>0.03</td>
      <td>0.03</td>
      <td>0.48</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.32</td>
      <td>0.27</td>
      <td>0.17</td>
      <td>0.16</td>
      <td>0.15</td>
      <td>0.26</td>
      <td>0.06</td>
      <td>0.00</td>
      <td>0.03</td>
      <td>0.11</td>
      <td>0.11</td>
      <td>0.19</td>
      <td>0.03</td>
      <td>0.06</td>
      <td>0.04</td>
      <td>0.22</td>
      <td>0.10</td>
      <td>0.00</td>
      <td>0.79</td>
      <td>0.21</td>
      <td>0.00</td>
      <td>0.34</td>
      <td>0.19</td>
      <td>0.27</td>
      <td>0.09</td>
      <td>0.22</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.54</td>
      <td>0.46</td>
      <td>0.00</td>
      <td>0.82</td>
      <td>0.17</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>894</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.48</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.32</td>
      <td>0.21</td>
      <td>0.19</td>
      <td>0.14</td>
      <td>0.12</td>
      <td>0.17</td>
      <td>0.14</td>
      <td>0.02</td>
      <td>0.04</td>
      <td>0.16</td>
      <td>0.21</td>
      <td>0.22</td>
      <td>0.09</td>
      <td>0.03</td>
      <td>0.06</td>
      <td>0.03</td>
      <td>0.11</td>
      <td>0.17</td>
      <td>0.80</td>
      <td>0.20</td>
      <td>0.00</td>
      <td>0.41</td>
      <td>0.21</td>
      <td>0.23</td>
      <td>0.08</td>
      <td>0.13</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.41</td>
      <td>0.59</td>
      <td>0.00</td>
      <td>0.82</td>
      <td>0.18</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>895</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.48</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.32</td>
      <td>0.25</td>
      <td>0.12</td>
      <td>0.16</td>
      <td>0.19</td>
      <td>0.15</td>
      <td>0.05</td>
      <td>0.00</td>
      <td>0.12</td>
      <td>0.15</td>
      <td>0.16</td>
      <td>0.20</td>
      <td>0.07</td>
      <td>0.02</td>
      <td>0.11</td>
      <td>0.24</td>
      <td>0.03</td>
      <td>0.06</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.00</td>
      <td>0.37</td>
      <td>0.20</td>
      <td>0.26</td>
      <td>0.07</td>
      <td>0.19</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.51</td>
      <td>0.49</td>
      <td>0.00</td>
      <td>0.95</td>
      <td>0.04</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>896</th>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.48</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1.00</td>
      <td>0.26</td>
      <td>0.25</td>
      <td>0.12</td>
      <td>0.15</td>
      <td>0.24</td>
      <td>0.18</td>
      <td>0.11</td>
      <td>0.01</td>
      <td>0.07</td>
      <td>0.23</td>
      <td>0.12</td>
      <td>0.18</td>
      <td>0.06</td>
      <td>0.08</td>
      <td>0.04</td>
      <td>0.20</td>
      <td>0.09</td>
      <td>0.30</td>
      <td>0.75</td>
      <td>0.25</td>
      <td>0.00</td>
      <td>0.42</td>
      <td>0.18</td>
      <td>0.22</td>
      <td>0.10</td>
      <td>0.15</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.38</td>
      <td>0.62</td>
      <td>0.00</td>
      <td>0.82</td>
      <td>0.17</td>
      <td>0.00</td>
      <td>0.01</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
  </tbody>
</table>
<p>897 rows × 45 columns</p>
</div>




```python
y_label.hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x2ae6f3ef4c8>




    
![png](output_39_1.png)
    



```python
y_label
```




    0      11.36
    2      10.66
    7       9.82
    8      11.50
    9       9.81
            ... 
    1639   10.06
    1640    8.69
    1641    9.49
    1642    9.76
    1643    9.79
    Name: TARGET, Length: 1019, dtype: float64




```python
y_label.describe()
```




    count     989.00
    mean    34606.50
    std     27680.32
    min        20.00
    25%     10800.00
    50%     27450.00
    75%     54250.00
    max     99540.00
    Name: TARGET, dtype: float64




```python
X_features['BID_COST'].hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x21042647cc8>




    
![png](output_42_1.png)
    



```python
X_features['CONFIG_BID_COST'].hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1d7d2b0a348>




    
![png](output_43_1.png)
    



```python
X_features['IMP_STRG_DOW'].hist()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x21042909cc8>




    
![png](output_44_1.png)
    



```python
X_features.columns
```




    Index(['BID_COST', 'CONFIG_BID_COST', 'IMP_STRG_DOW', 'BOOST_USE_CONFIG_YN',
           'EQD_USE_CONFIG_YN', 'AD_TYPE', 'ADDR_SO', 'ADDR_GG', 'ADDR_BS',
           'ADDR_IC', 'ADDR_KN', 'ADDR_DG', 'ADDR_KB', 'ADDR_ALL', 'ADDR_DJ',
           'ADDR_JB', 'ADDR_GJ', 'ADDR_CN', 'ADDR_CB', 'ADDR_US', 'ADDR_JN',
           'ADDR_GW', 'ADDR_JJ', 'ADDR_SJ', 'MACH_ANDROID', 'MACH_IOS', 'MACH_PC',
           'AGE_40', 'AGE_30', 'AGE_50', 'AGE_20', 'AGE_60', 'AGE_ALL', 'AGE_10',
           'GENDER_F', 'GENDER_M', 'GENDER_N', 'INV_M01A01001', 'INV_M01A01002',
           'INV_M01A05001', 'INV_M01A01003', 'INV_M01M02001', 'INV_M01M01001',
           'INV_M01M03001', 'INV_M01A06001'],
          dtype='object')



인벤토리 삭제


```python
X_features = X_features.drop(['INV_M01A01001', 'INV_M01A01002','INV_M01A05001', 'INV_M01A01003', 'INV_M01M02001',
                              'INV_M01M01001','INV_M01M03001', 'INV_M01A06001'],axis=1)
```


```python
X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=0.2, random_state=156)
```


```python
print(X_train.shape , X_test.shape)
```

    (717, 45) (180, 45)


# 모델 학습 시작

### 그리드서치


```python
from sklearn.model_selection import GridSearchCV
# 랜덤포레스트 그리드서치
param_grid = [
    {'n_estimators' : [3,10,30,50,100], 'max_features': [1,2,4,6,8,10,20],'max_depth':[None,3,5,8]}]
model = RandomForestRegressor()
grid_search = GridSearchCV(model, param_grid, cv=5,
                          scoring='neg_mean_squared_error',
                          return_train_score=True)
grid_search.fit(X_train,y_train)
```




    GridSearchCV(cv=5, error_score=nan,
                 estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,
                                                 criterion='mse', max_depth=None,
                                                 max_features='auto',
                                                 max_leaf_nodes=None,
                                                 max_samples=None,
                                                 min_impurity_decrease=0.0,
                                                 min_impurity_split=None,
                                                 min_samples_leaf=1,
                                                 min_samples_split=2,
                                                 min_weight_fraction_leaf=0.0,
                                                 n_estimators=100, n_jobs=None,
                                                 oob_score=False, random_state=None,
                                                 verbose=0, warm_start=False),
                 iid='deprecated', n_jobs=None,
                 param_grid=[{'max_depth': [None, 3, 5, 8],
                              'max_features': [1, 2, 4, 6, 8, 10, 20],
                              'n_estimators': [3, 10, 30, 50, 100]}],
                 pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
                 scoring='neg_mean_squared_error', verbose=0)




```python
print(grid_search.best_params_)
cvres = grid_search.cv_results_
for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
    print(np.sqrt(-mean_score), params)
```

    {'max_depth': None, 'max_features': 10, 'n_estimators': 100}
    0.870597323689582 {'max_depth': None, 'max_features': 1, 'n_estimators': 3}
    0.780040038996717 {'max_depth': None, 'max_features': 1, 'n_estimators': 10}
    0.7397465630293598 {'max_depth': None, 'max_features': 1, 'n_estimators': 30}
    0.7306752620112018 {'max_depth': None, 'max_features': 1, 'n_estimators': 50}
    0.7299636783032494 {'max_depth': None, 'max_features': 1, 'n_estimators': 100}
    0.9028038744870617 {'max_depth': None, 'max_features': 2, 'n_estimators': 3}
    0.75542116743014 {'max_depth': None, 'max_features': 2, 'n_estimators': 10}
    0.7143854484252802 {'max_depth': None, 'max_features': 2, 'n_estimators': 30}
    0.6965202411706022 {'max_depth': None, 'max_features': 2, 'n_estimators': 50}
    0.6965383945617546 {'max_depth': None, 'max_features': 2, 'n_estimators': 100}
    0.9240256530264408 {'max_depth': None, 'max_features': 4, 'n_estimators': 3}
    0.7301660876238975 {'max_depth': None, 'max_features': 4, 'n_estimators': 10}
    0.6842245594191582 {'max_depth': None, 'max_features': 4, 'n_estimators': 30}
    0.6632125754365485 {'max_depth': None, 'max_features': 4, 'n_estimators': 50}
    0.6644906653406757 {'max_depth': None, 'max_features': 4, 'n_estimators': 100}
    0.8153564838681993 {'max_depth': None, 'max_features': 6, 'n_estimators': 3}
    0.7022093144242504 {'max_depth': None, 'max_features': 6, 'n_estimators': 10}
    0.6531937363921948 {'max_depth': None, 'max_features': 6, 'n_estimators': 30}
    0.6591272052095439 {'max_depth': None, 'max_features': 6, 'n_estimators': 50}
    0.6408829699986852 {'max_depth': None, 'max_features': 6, 'n_estimators': 100}
    0.7996686000384743 {'max_depth': None, 'max_features': 8, 'n_estimators': 3}
    0.6770419539917699 {'max_depth': None, 'max_features': 8, 'n_estimators': 10}
    0.6584808063136001 {'max_depth': None, 'max_features': 8, 'n_estimators': 30}
    0.6452910252115508 {'max_depth': None, 'max_features': 8, 'n_estimators': 50}
    0.6435964694728761 {'max_depth': None, 'max_features': 8, 'n_estimators': 100}
    0.8028661370933309 {'max_depth': None, 'max_features': 10, 'n_estimators': 3}
    0.7007707408893038 {'max_depth': None, 'max_features': 10, 'n_estimators': 10}
    0.649147200084611 {'max_depth': None, 'max_features': 10, 'n_estimators': 30}
    0.6392337731968027 {'max_depth': None, 'max_features': 10, 'n_estimators': 50}
    0.635024780518778 {'max_depth': None, 'max_features': 10, 'n_estimators': 100}
    0.7947203688162732 {'max_depth': None, 'max_features': 20, 'n_estimators': 3}
    0.6835248802892783 {'max_depth': None, 'max_features': 20, 'n_estimators': 10}
    0.6637724952439302 {'max_depth': None, 'max_features': 20, 'n_estimators': 30}
    0.6427169699745487 {'max_depth': None, 'max_features': 20, 'n_estimators': 50}
    0.6448327972666477 {'max_depth': None, 'max_features': 20, 'n_estimators': 100}
    1.070286695625611 {'max_depth': 3, 'max_features': 1, 'n_estimators': 3}
    0.9860699264465593 {'max_depth': 3, 'max_features': 1, 'n_estimators': 10}
    1.006949375503157 {'max_depth': 3, 'max_features': 1, 'n_estimators': 30}
    1.0173388166151955 {'max_depth': 3, 'max_features': 1, 'n_estimators': 50}
    1.0003514453633506 {'max_depth': 3, 'max_features': 1, 'n_estimators': 100}
    0.97989907031225 {'max_depth': 3, 'max_features': 2, 'n_estimators': 3}
    0.9702439926170286 {'max_depth': 3, 'max_features': 2, 'n_estimators': 10}
    0.9308355632774288 {'max_depth': 3, 'max_features': 2, 'n_estimators': 30}
    0.9526688407608185 {'max_depth': 3, 'max_features': 2, 'n_estimators': 50}
    0.9315673768531748 {'max_depth': 3, 'max_features': 2, 'n_estimators': 100}
    0.9539603212369051 {'max_depth': 3, 'max_features': 4, 'n_estimators': 3}
    0.8984608724004454 {'max_depth': 3, 'max_features': 4, 'n_estimators': 10}
    0.8957222032256338 {'max_depth': 3, 'max_features': 4, 'n_estimators': 30}
    0.894438078565043 {'max_depth': 3, 'max_features': 4, 'n_estimators': 50}
    0.8846321197540762 {'max_depth': 3, 'max_features': 4, 'n_estimators': 100}
    0.9262916882664053 {'max_depth': 3, 'max_features': 6, 'n_estimators': 3}
    0.8588896403512111 {'max_depth': 3, 'max_features': 6, 'n_estimators': 10}
    0.854275641090902 {'max_depth': 3, 'max_features': 6, 'n_estimators': 30}
    0.8576852974720526 {'max_depth': 3, 'max_features': 6, 'n_estimators': 50}
    0.8607136278797967 {'max_depth': 3, 'max_features': 6, 'n_estimators': 100}
    0.9383971371200468 {'max_depth': 3, 'max_features': 8, 'n_estimators': 3}
    0.8545793848934606 {'max_depth': 3, 'max_features': 8, 'n_estimators': 10}
    0.8413592358307054 {'max_depth': 3, 'max_features': 8, 'n_estimators': 30}
    0.8502227928229237 {'max_depth': 3, 'max_features': 8, 'n_estimators': 50}
    0.8369858140754932 {'max_depth': 3, 'max_features': 8, 'n_estimators': 100}
    0.9006728982041469 {'max_depth': 3, 'max_features': 10, 'n_estimators': 3}
    0.8462288232542113 {'max_depth': 3, 'max_features': 10, 'n_estimators': 10}
    0.8398086792548594 {'max_depth': 3, 'max_features': 10, 'n_estimators': 30}
    0.8466442157551934 {'max_depth': 3, 'max_features': 10, 'n_estimators': 50}
    0.8324867575787898 {'max_depth': 3, 'max_features': 10, 'n_estimators': 100}
    0.8767354079921901 {'max_depth': 3, 'max_features': 20, 'n_estimators': 3}
    0.8181700873425629 {'max_depth': 3, 'max_features': 20, 'n_estimators': 10}
    0.8055956861448382 {'max_depth': 3, 'max_features': 20, 'n_estimators': 30}
    0.8162236917475545 {'max_depth': 3, 'max_features': 20, 'n_estimators': 50}
    0.8100405298597538 {'max_depth': 3, 'max_features': 20, 'n_estimators': 100}
    0.9395138667564357 {'max_depth': 5, 'max_features': 1, 'n_estimators': 3}
    0.9306274131438322 {'max_depth': 5, 'max_features': 1, 'n_estimators': 10}
    0.8895656227889951 {'max_depth': 5, 'max_features': 1, 'n_estimators': 30}
    0.9011491942995341 {'max_depth': 5, 'max_features': 1, 'n_estimators': 50}
    0.9063442793321372 {'max_depth': 5, 'max_features': 1, 'n_estimators': 100}
    0.9815962473560725 {'max_depth': 5, 'max_features': 2, 'n_estimators': 3}
    0.8796607149915354 {'max_depth': 5, 'max_features': 2, 'n_estimators': 10}
    0.8272603003942552 {'max_depth': 5, 'max_features': 2, 'n_estimators': 30}
    0.8297974208652746 {'max_depth': 5, 'max_features': 2, 'n_estimators': 50}
    0.8336701918033048 {'max_depth': 5, 'max_features': 2, 'n_estimators': 100}
    0.8701812465807505 {'max_depth': 5, 'max_features': 4, 'n_estimators': 3}
    0.7787290347181435 {'max_depth': 5, 'max_features': 4, 'n_estimators': 10}
    0.765000771346334 {'max_depth': 5, 'max_features': 4, 'n_estimators': 30}
    0.7651843204045742 {'max_depth': 5, 'max_features': 4, 'n_estimators': 50}
    0.7583258913283325 {'max_depth': 5, 'max_features': 4, 'n_estimators': 100}
    0.8839175935643534 {'max_depth': 5, 'max_features': 6, 'n_estimators': 3}
    0.7579084441257631 {'max_depth': 5, 'max_features': 6, 'n_estimators': 10}
    0.7321510109354853 {'max_depth': 5, 'max_features': 6, 'n_estimators': 30}
    0.7275548477464111 {'max_depth': 5, 'max_features': 6, 'n_estimators': 50}
    0.735337741845468 {'max_depth': 5, 'max_features': 6, 'n_estimators': 100}
    0.8520730082113006 {'max_depth': 5, 'max_features': 8, 'n_estimators': 3}
    0.7516956453843966 {'max_depth': 5, 'max_features': 8, 'n_estimators': 10}
    0.7199673602659922 {'max_depth': 5, 'max_features': 8, 'n_estimators': 30}
    0.7201059103886831 {'max_depth': 5, 'max_features': 8, 'n_estimators': 50}
    0.7228666833068725 {'max_depth': 5, 'max_features': 8, 'n_estimators': 100}
    0.8083642925714893 {'max_depth': 5, 'max_features': 10, 'n_estimators': 3}
    0.7344184658817402 {'max_depth': 5, 'max_features': 10, 'n_estimators': 10}
    0.7282647248585581 {'max_depth': 5, 'max_features': 10, 'n_estimators': 30}
    0.6990982105959048 {'max_depth': 5, 'max_features': 10, 'n_estimators': 50}
    0.7052897443777109 {'max_depth': 5, 'max_features': 10, 'n_estimators': 100}
    0.7864761177307102 {'max_depth': 5, 'max_features': 20, 'n_estimators': 3}
    0.7238091168117377 {'max_depth': 5, 'max_features': 20, 'n_estimators': 10}
    0.6947312025209555 {'max_depth': 5, 'max_features': 20, 'n_estimators': 30}
    0.6911574665766202 {'max_depth': 5, 'max_features': 20, 'n_estimators': 50}
    0.6945874056500875 {'max_depth': 5, 'max_features': 20, 'n_estimators': 100}
    0.9155786168272724 {'max_depth': 8, 'max_features': 1, 'n_estimators': 3}
    0.8581593856533491 {'max_depth': 8, 'max_features': 1, 'n_estimators': 10}
    0.8168254747583843 {'max_depth': 8, 'max_features': 1, 'n_estimators': 30}
    0.8096608721626535 {'max_depth': 8, 'max_features': 1, 'n_estimators': 50}
    0.7963692276321322 {'max_depth': 8, 'max_features': 1, 'n_estimators': 100}
    0.8725232325295595 {'max_depth': 8, 'max_features': 2, 'n_estimators': 3}
    0.7635345684250011 {'max_depth': 8, 'max_features': 2, 'n_estimators': 10}
    0.7546988661198167 {'max_depth': 8, 'max_features': 2, 'n_estimators': 30}
    0.7473595355082066 {'max_depth': 8, 'max_features': 2, 'n_estimators': 50}
    0.7371102291209637 {'max_depth': 8, 'max_features': 2, 'n_estimators': 100}
    0.8339632072283384 {'max_depth': 8, 'max_features': 4, 'n_estimators': 3}
    0.742611705854518 {'max_depth': 8, 'max_features': 4, 'n_estimators': 10}
    0.6994735695369716 {'max_depth': 8, 'max_features': 4, 'n_estimators': 30}
    0.6989916947047944 {'max_depth': 8, 'max_features': 4, 'n_estimators': 50}
    0.6735931811773986 {'max_depth': 8, 'max_features': 4, 'n_estimators': 100}
    0.8288885092092247 {'max_depth': 8, 'max_features': 6, 'n_estimators': 3}
    0.6970142017827552 {'max_depth': 8, 'max_features': 6, 'n_estimators': 10}
    0.6743036197249926 {'max_depth': 8, 'max_features': 6, 'n_estimators': 30}
    0.6640031114642687 {'max_depth': 8, 'max_features': 6, 'n_estimators': 50}
    0.6628760471849324 {'max_depth': 8, 'max_features': 6, 'n_estimators': 100}
    0.8242447649632135 {'max_depth': 8, 'max_features': 8, 'n_estimators': 3}
    0.6952381455604821 {'max_depth': 8, 'max_features': 8, 'n_estimators': 10}
    0.6723062866435922 {'max_depth': 8, 'max_features': 8, 'n_estimators': 30}
    0.6556448300959364 {'max_depth': 8, 'max_features': 8, 'n_estimators': 50}
    0.6532085153920226 {'max_depth': 8, 'max_features': 8, 'n_estimators': 100}
    0.8208557132760341 {'max_depth': 8, 'max_features': 10, 'n_estimators': 3}
    0.698391629840804 {'max_depth': 8, 'max_features': 10, 'n_estimators': 10}
    0.6498111957378643 {'max_depth': 8, 'max_features': 10, 'n_estimators': 30}
    0.64087225327578 {'max_depth': 8, 'max_features': 10, 'n_estimators': 50}
    0.6424574089388387 {'max_depth': 8, 'max_features': 10, 'n_estimators': 100}
    0.7844428858481638 {'max_depth': 8, 'max_features': 20, 'n_estimators': 3}
    0.6845137419081535 {'max_depth': 8, 'max_features': 20, 'n_estimators': 10}
    0.652888231200759 {'max_depth': 8, 'max_features': 20, 'n_estimators': 30}
    0.6529291353617 {'max_depth': 8, 'max_features': 20, 'n_estimators': 50}
    0.6426915272695753 {'max_depth': 8, 'max_features': 20, 'n_estimators': 100}



```python
from sklearn.model_selection import GridSearchCV
# XGBOOST  그리드서치
param_grid = [
    {'n_estimators' : [180,190,200,210,220], 
     'max_depth': [4], 'learning_rate':[0.1,0.05,0.04,0.03]}]
model_xgb = xgb.XGBRegressor()
xgb_grid_search = GridSearchCV(model_xgb, param_grid, cv=5,
                          scoring='neg_mean_squared_error',
                          return_train_score=True)
xgb_grid_search.fit(X_train,y_train)
```

    [14:44:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:23] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:33] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:33] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:33] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:36] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:36] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:37] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:37] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:49] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:49] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [14:44:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.





    GridSearchCV(cv=5, error_score=nan,
                 estimator=XGBRegressor(base_score=0.5, booster='gbtree',
                                        colsample_bylevel=1, colsample_bynode=1,
                                        colsample_bytree=1, gamma=0,
                                        importance_type='gain', learning_rate=0.1,
                                        max_delta_step=0, max_depth=3,
                                        min_child_weight=1, missing=None,
                                        n_estimators=100, n_jobs=1, nthread=None,
                                        objective='reg:linear', random_state=0,
                                        reg_alpha=0, reg_lambda=1,
                                        scale_pos_weight=1, seed=None, silent=None,
                                        subsample=1, verbosity=1),
                 iid='deprecated', n_jobs=None,
                 param_grid=[{'learning_rate': [0.1, 0.05, 0.04, 0.03],
                              'max_depth': [4],
                              'n_estimators': [180, 190, 200, 210, 220]}],
                 pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
                 scoring='neg_mean_squared_error', verbose=0)




```python
print(xgb_grid_search.best_params_)
cvres = xgb_grid_search.cv_results_
for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
    print(np.sqrt(-mean_score), params)
```

    {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 220}
    0.601924312147307 {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 180}
    0.602188314036274 {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 190}
    0.6027751079281602 {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200}
    0.6030048175210515 {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 210}
    0.6029578118864274 {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 220}
    0.5910730761790081 {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 180}
    0.5907659564460767 {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 190}
    0.5903624818935508 {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 200}
    0.5900669534315316 {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 210}
    0.5896326446417757 {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 220}
    0.5949557139605991 {'learning_rate': 0.04, 'max_depth': 4, 'n_estimators': 180}
    0.5943880168651533 {'learning_rate': 0.04, 'max_depth': 4, 'n_estimators': 190}
    0.5936099102350596 {'learning_rate': 0.04, 'max_depth': 4, 'n_estimators': 200}
    0.5932555551178225 {'learning_rate': 0.04, 'max_depth': 4, 'n_estimators': 210}
    0.5930016621313291 {'learning_rate': 0.04, 'max_depth': 4, 'n_estimators': 220}
    0.6007006977999131 {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 180}
    0.5978922866090597 {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 190}
    0.5961069369031295 {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 200}
    0.594639271685085 {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 210}
    0.5933439217545228 {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 220}



```python
from sklearn.model_selection import GridSearchCV
# XGBOOST  그리드서치
param_grid = [
    {'n_estimators' : [180,190,200,210,220], 
     'max_depth': [4], 'learning_rate':[0.1,0.05,0.04,0.03]}]
model_xgb = xgb.XGBRegressor()
xgb_grid_search = GridSearchCV(model_xgb, param_grid, cv=5,
                          scoring='neg_mean_squared_error',
                          return_train_score=True)
xgb_grid_search.fit(X_train,y_train)
```




    GridSearchCV(cv=5,
                 estimator=XGBRegressor(base_score=None, booster=None,
                                        colsample_bylevel=None,
                                        colsample_bynode=None,
                                        colsample_bytree=None, gamma=None,
                                        gpu_id=None, importance_type='gain',
                                        interaction_constraints=None,
                                        learning_rate=None, max_delta_step=None,
                                        max_depth=None, min_child_weight=None,
                                        missing=nan, monotone_constraints=None,
                                        n_estimators=100, n_jobs=None,
                                        num_parallel_tree=None, random_state=None,
                                        reg_alpha=None, reg_lambda=None,
                                        scale_pos_weight=None, subsample=None,
                                        tree_method=None, validate_parameters=None,
                                        verbosity=None),
                 param_grid=[{'learning_rate': [0.1, 0.05, 0.04, 0.03],
                              'max_depth': [4],
                              'n_estimators': [180, 190, 200, 210, 220]}],
                 return_train_score=True, scoring='neg_mean_squared_error')




```python
em = xgb_grid_search.best_estimator_
pred = em.predict(X_test)
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(np.exp(pred), np.exp(y_test))
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(pred, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

    Mean Absolute Error : 0.36040700168937306
    root_mean_squared_error : 16307.580068432788



```python
# XGBOOST 모델 학습
model_xgb = xgb.XGBRegressor(random_state=156, learning_rate = 0.05, max_depth = 4, n_estimators = 220)
#model_xgb = xgb.XGBRegressor(random_state=156, n_estimators=1000)

model_xgb.fit(X_train,y_train)
# XGBOOST 모델 예측
predictions = model_xgb.predict(X_test)
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(np.exp(predictions), np.exp(y_test))
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

    [14:45:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    Mean Absolute Error : 0.3604068215508911
    root_mean_squared_error : 16307.570344860671


Random Search


```python
def report_best_scores(results, n_top=3):
    for i in range(1, n_top + 1):
        candidates = np.flatnonzero(results['rank_test_score'] == i)
        for candidate in candidates:
            print("Model with rank: {0}".format(i))
            print("Mean validation score: {0:.3f} (std: {1:.3f})".format(
                  results['mean_test_score'][candidate],
                  results['std_test_score'][candidate]))
            print("Parameters: {0}".format(results['params'][candidate]))
            print("")
```


```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform, randint

# XGBOOST  랜덤서치
model_xgb = xgb.XGBRegressor(objective ='reg:squarederror')
param = [
    {'n_estimators' : [100,300], 'max_depth': list(range(2,10)),'learning_rate' : [0.1,0.05,0.01]}]
model_xgb = xgb.XGBRegressor()
xgb_ran_search = RandomizedSearchCV(model_xgb, param_distributions=param, cv=5,
                          scoring='neg_mean_squared_error',
                          return_train_score=True, random_state=156)
xgb_ran_search.fit(X_train,y_train)
report_best_scores(xgb_ran_search.cv_results_, 1)
```

    [11:36:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:49] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:36:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:02] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:04] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:04] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:07] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    [11:37:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
    Model with rank: 1
    Mean validation score: -0.339 (std: 0.047)
    Parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.1}
    



```python
# XGBOOST 모델 학습
model_xgb = xgb.XGBRegressor(random_state=156, learning_rate = 0.05, max_depth = 5, n_estimators = 300
                            , objective='reg:squarederror')
#model_xgb = xgb.XGBRegressor(random_state=156, n_estimators=1000)
model_xgb.fit(X_train,y_train)
# XGBOOST 모델 예측
predictions = model_xgb.predict(X_test) 
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(np.exp(predictions), np.exp(y_test))
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

    Mean Absolute Error : 0.37044767866334827
    root_mean_squared_error : 16388.074817401757



```python
# XGBOOST 모델 학습
model_xgb = xgb.XGBRegressor(random_state=156, learning_rate = 0.05, max_depth = 5, n_estimators = 300
                            , objective='reg:squarederror')
#model_xgb = xgb.XGBRegressor(random_state=156, n_estimators=1000)
model_xgb.fit(X_train,y_train)
# XGBOOST 모델 예측
predictions = model_xgb.predict(X_test) 
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(np.exp(predictions), np.exp(y_test))
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

    Mean Absolute Error : 0.3704477899253519
    root_mean_squared_error : 16388.07610811478



```python
# XGBOOST 모델 학습
model_xgb = xgb.XGBRegressor(random_state=156
                            , objective='reg:squarederror')
#model_xgb = xgb.XGBRegressor(random_state=156, n_estimators=1000)
model_xgb.fit(X_train,y_train)
# XGBOOST 모델 예측
predictions = model_xgb.predict(X_test) 
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(np.exp(predictions), np.exp(y_test))
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

    Mean Absolute Error : 0.363445722154735
    root_mean_squared_error : 16577.24339878323



```python
# XGBOOST 모델 학습
model_xgb = xgb.XGBRegressor(random_state=156
                            , objective='reg:squarederror')
#model_xgb = xgb.XGBRegressor(random_state=156, n_estimators=1000)
model_xgb.fit(X_train,y_train)
# XGBOOST 모델 예측
predictions = model_xgb.predict(X_test) 
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(np.exp(predictions), np.exp(y_test))
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

    Mean Absolute Error : 0.4006383997159053
    root_mean_squared_error : 16961.156054195464


### Logistic Regression
데이터를 사용하기전에 반드시 정규화를 사용해줘야 함
ex) StandardScaler


```python
model_LR= LogisticRegression(random_state=156)
model_LR.fit(X_train, y_train)
# LR 모델 예측
predictions = model_LR.predict(X_test)
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(predictions, y_test)
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

### RIDGE


```python
from sklearn.linear_model import Ridge
model_RIDGE= Ridge(random_state=156)
model_RIDGE.fit(X_train, y_train)
# LR 모델 예측
predictions = model_RIDGE.predict(X_test)
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(predictions, y_test)
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

### LASSO


```python
from sklearn.linear_model import Lasso
model_Lasso= Lasso(random_state=156)
model_Lasso.fit(X_train, y_train)
# LR 모델 예측
predictions = model_Lasso.predict(X_test)
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(predictions, y_test)
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

### MLP
https://frhyme.github.io/python-lib/is_mlp_regressor_good/


```python
from sklearn.neural_network import MLPRegressor

```

### SVM - Regression


```python
from sklearn.svm import LinearSVR
model_SVR = LinearSVR(random_state=156)
model_SVR.fit(X_train,y_train)
# RF 모델 예측
predictions = model_SVR.predict(X_test)
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(predictions, y_test)
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

### RF


```python
# RF 모델 학습
model_rf =  RandomForestRegressor(random_state=156)
model_rf.fit(X_train,y_train)
# RF 모델 예측
predictions = model_rf.predict(X_test)
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(predictions, y_test)
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

### XGBOOST


```python
# XGBOOST 모델 학습
model_xgb = xgb.XGBRegressor(random_state=156, learning_rate = 0.05, max_depth = 5, n_estimators = 300
                            , objective='reg:squarederror')
#model_xgb = xgb.XGBRegressor(random_state=156, n_estimators=1000)
model_xgb.fit(X_train,y_train)
# XGBOOST 모델 예측
predictions = model_xgb.predict(X_test) 
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(np.exp(predictions), np.exp(y_test))
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```

    Mean Absolute Error : 0.37044767866334827
    root_mean_squared_error : 16388.074817401757



```python
# 신뢰구간
from scipy import stats

confidence = 0.95
squared_errors = (np.exp(predictions)- np.exp(y_test)) ** 2
np.sqrt(stats.t.interval(confidence, len(squared_errors) -1,
                        loc=squared_errors.mean(),
                        scale=stats.sem(squared_errors)))
```




    array([13737.66621709, 18665.86508441])




```python
plt.figure(figsize=(20,10))
plt.plot(range(len(y_test)), np.array(np.exp(y_test)), linewidth=4, alpha = 0.3)
plt.plot(range(len(y_test)), np.array(np.exp(predictions)), linewidth=4, alpha = 0.3)
plt.legend(['real', 'predict'], loc=7)
plt.show()
```


    
![png](output_81_0.png)
    


log scale


```python
# XGBOOST 모델 학습
model_xgb = xgb.XGBRegressor(random_state=156, learning_rate = 0.07, max_depth = 4, n_estimators = 150)
#model_xgb = xgb.XGBRegressor(random_state=156, n_estimators=1000)

model_xgb.fit(X_train,y_train)
# XGBOOST 모델 예측
predictions = model_xgb.predict(X_test)
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(np.exp(predictions), np.exp(y_test))
rmse = np.sqrt(mse)
print("Mean Absolute Error : " + str(mean_absolute_error(predictions, y_test)))
print("root_mean_squared_error : " + str(rmse))
```


```python
# XGBOOST feature importance
from xgboost import plot_importance
fig, ax = plt.subplots(figsize=(10,12))
plot_importance(model_xgb, ax=ax)
```


```python
from sklearn.model_selection import RandomizedSearchCV
# XGBoost 분류기 생성
model_xgb = xgb.XGBRegressor(random_state=156)
# 초모수 격자생성
xgb_param_grid = {'max_depth': list(range(2,10)), 
                  'subsample': np.linspace(0.4, 1, 7)}
# Create a random search object
xgb_random = RandomizedSearchCV(estimator = xgb_clf,
                                param_distributions = xgb_param_grid,
                                n_iter = 10,
                                scoring='roc_auc', 
                                n_jobs=8, 
                                cv = 3, 
                                refit=True, 
                                return_train_score = True)
# Fit to the training data
xgb_random.fit(X_train, y_train)
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-42-780109f1bdfa> in <module>
          6                   'subsample': np.linspace(0.4, 1, 7)}
          7 # Create a random search object
    ----> 8 xgb_random = RandomizedSearchCV(estimator = xgb_clf,
          9                                 param_distributions = xgb_param_grid,
         10                                 n_iter = 10,


    NameError: name 'xgb_clf' is not defined



```python
print(xgb_grid_search.best_params_)
cvres = xgb_grid_search.cv_results_
for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
    print(np.sqrt(-mean_score), params)
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-88-2cf6990fd4d6> in <module>
    ----> 1 print(xgb_grid_search.best_params_)
          2 cvres = xgb_grid_search.cv_results_
          3 for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
          4     print(np.sqrt(-mean_score), params)


    NameError: name 'xgb_grid_search' is not defined



```python
# 신뢰구간
from scipy import stats

confidence = 0.95
squared_errors = (predictions- y_test) ** 2
np.sqrt(stats.t.interval(confidence, len(squared_errors) -1,
                        loc=squared_errors.mean(),
                        scale=stats.sem(squared_errors)))
```




    array([ 81490.0897347 , 199028.87028968])




```python
plt.plot(range(len(y_test)), np.array(y_test))
plt.plot(range(len(y_test)), np.array(predictions))
plt.legend(['real', 'predict'], loc=7)
plt.show()
```


    
![png](output_88_0.png)
    



```python
y_label.sort_values(ascending=False)
```




    1429    99540
    131     99257
    8       99150
    1616    99128
    868     98800
            ...  
    536        85
    1188       85
    1577       71
    765        50
    100        14
    Name: TARGET, Length: 1019, dtype: int64




```python

```
